[2022-06-14 10:45:52,046] Namespace(auto_augment=True, batch_size=1024, data_dir='/dataset/public/ImageNetOrigin/', epoch=480, lr=0.6, mode='Train', nesterov=True, reduction=1.375, results_dir='./results/', resume=None)
[2022-06-14 10:45:52,046] ==> Preparing data..
[2022-06-14 10:46:00,774] Training / Testing data number: 50000 / 1281167
[2022-06-14 10:46:00,775] Using path: ./results/14104552/
[2022-06-14 10:46:00,775] ==> Building model..
[2022-06-14 10:46:04,857] DataParallel(
  (module): FENet(
    (conv1): Conv2d(3, 22, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (ibssl): IBSSL(
      (conv1): Conv2d(22, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shift2): SSL2d()
      (conv2): Conv2d(88, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (ibpool): IBPool(
      (conv1): Conv2d(22, 220, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(220, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (shift2): AvgPool2d(kernel_size=2, stride=2, padding=0)
      (conv2): Conv2d(220, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (feblock1): FEBlock3n2s(
      (resibssl_1): ResIBSSL(
        (conv1): Conv2d(11, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(66, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_2): ResIBSSL(
        (conv1): Conv2d(22, 132, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(132, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (ibpool): IBPool(
        (conv1): Conv2d(44, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv2): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (feblock2): FEBlock4n2s(
      (resibssl_1): ResIBSSL(
        (conv1): Conv2d(11, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(66, 11, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(11, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_2): ResIBSSL(
        (conv1): Conv2d(22, 132, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(132, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_3): ResIBSSL(
        (conv1): Conv2d(44, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(264, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (ibpool): IBPool(
        (conv1): Conv2d(88, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv2): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (feblock3): FEBlock4n1s(
      (resibssl_1): ResIBSSL(
        (conv1): Conv2d(22, 132, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(132, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_2): ResIBSSL(
        (conv1): Conv2d(44, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(264, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_3): ResIBSSL(
        (conv1): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (ibssl): IBSSL(
        (conv1): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (feblock4): FEBlock4n2s(
      (resibssl_1): ResIBSSL(
        (conv1): Conv2d(22, 132, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(132, 22, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_2): ResIBSSL(
        (conv1): Conv2d(44, 264, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(264, 44, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_3): ResIBSSL(
        (conv1): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (ibpool): IBPool(
        (conv1): Conv2d(176, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): AvgPool2d(kernel_size=2, stride=2, padding=0)
        (conv2): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (feblock5): FEBlock3n1s(
      (resibssl_1): ResIBSSL(
        (conv1): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (resibssl_2): ResIBSSL(
        (conv1): Conv2d(176, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(1056, 176, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(176, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (ibssl): IBSSL(
        (conv1): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (shift2): SSL2d()
        (conv2): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn2): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (conv2): Conv2d(352, 1932, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn2): BatchNorm2d(1932, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (gap): AdaptiveAvgPool2d(output_size=(1, 1))
    (dropout): Dropout(p=0.2, inplace=False)
    (fc): Conv2d(1932, 1000, kernel_size=(1, 1), stride=(1, 1))
  )
)
[2022-06-14 10:46:04,866] Epoch: 0
[2022-06-14 11:05:39,178] Train: Loss: 5.822 | Acc: 4.267 (54667/1281167) | Lr: 0.6
[2022-06-14 11:06:28,947] Test: Loss: 5.160 | Acc: 8.358 (4179/50000)
[2022-06-14 11:06:28,948] Saving..
[2022-06-14 11:06:29,051] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 11:06:29,052] Epoch: 1
[2022-06-14 11:24:16,374] Train: Loss: 4.343 | Acc: 16.825 (215550/1281167) | Lr: 0.5999935746063304
[2022-06-14 11:25:05,788] Test: Loss: 4.006 | Acc: 20.324 (10162/50000)
[2022-06-14 11:25:05,788] Saving..
[2022-06-14 11:25:05,871] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 11:25:05,871] Epoch: 2
[2022-06-14 11:42:53,102] Train: Loss: 3.716 | Acc: 25.458 (326160/1281167) | Lr: 0.5999742987005642
[2022-06-14 11:43:42,175] Test: Loss: 3.340 | Acc: 28.888 (14444/50000)
[2022-06-14 11:43:42,175] Saving..
[2022-06-14 11:43:42,253] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 11:43:42,253] Epoch: 3
[2022-06-14 12:01:31,557] Train: Loss: 3.396 | Acc: 30.344 (388752/1281167) | Lr: 0.599942173108417
[2022-06-14 12:02:20,770] Test: Loss: 3.324 | Acc: 30.442 (15221/50000)
[2022-06-14 12:02:20,771] Saving..
[2022-06-14 12:02:20,842] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 12:02:20,842] Epoch: 4
[2022-06-14 12:20:03,017] Train: Loss: 3.207 | Acc: 33.375 (427595/1281167) | Lr: 0.5998971992060422
[2022-06-14 12:20:51,303] Test: Loss: 3.034 | Acc: 34.352 (17176/50000)
[2022-06-14 12:20:51,303] Saving..
[2022-06-14 12:20:51,380] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 12:20:51,380] Epoch: 5
[2022-06-14 12:38:37,697] Train: Loss: 3.082 | Acc: 35.418 (453766/1281167) | Lr: 0.5998393789199723
[2022-06-14 12:39:27,486] Test: Loss: 3.048 | Acc: 34.212 (17106/50000)
[2022-06-14 12:39:27,486] Epoch: 6
[2022-06-14 12:57:22,915] Train: Loss: 2.978 | Acc: 37.121 (475580/1281167) | Lr: 0.5997687147270356
[2022-06-14 12:58:14,349] Test: Loss: 2.906 | Acc: 37.420 (18710/50000)
[2022-06-14 12:58:14,349] Saving..
[2022-06-14 12:58:14,437] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 12:58:14,438] Epoch: 7
[2022-06-14 13:15:57,139] Train: Loss: 2.906 | Acc: 38.305 (490747/1281167) | Lr: 0.5996852096542512
[2022-06-14 13:16:50,274] Test: Loss: 3.140 | Acc: 32.892 (16446/50000)
[2022-06-14 13:16:50,274] Epoch: 8
[2022-06-14 13:34:29,756] Train: Loss: 2.848 | Acc: 39.316 (503703/1281167) | Lr: 0.5995888672786983
[2022-06-14 13:35:21,809] Test: Loss: 2.732 | Acc: 39.710 (19855/50000)
[2022-06-14 13:35:21,809] Saving..
[2022-06-14 13:35:21,896] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 13:35:21,896] Epoch: 9
[2022-06-14 13:53:05,453] Train: Loss: 2.797 | Acc: 40.189 (514882/1281167) | Lr: 0.5994796917273638
[2022-06-14 13:53:57,068] Test: Loss: 2.762 | Acc: 39.886 (19943/50000)
[2022-06-14 13:53:57,068] Saving..
[2022-06-14 13:53:57,240] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 13:53:57,240] Epoch: 10
[2022-06-14 14:11:47,990] Train: Loss: 2.758 | Acc: 40.885 (523804/1281167) | Lr: 0.5993576876769647
[2022-06-14 14:12:39,554] Test: Loss: 2.603 | Acc: 42.324 (21162/50000)
[2022-06-14 14:12:39,555] Saving..
[2022-06-14 14:12:39,641] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 14:12:39,642] Epoch: 11
[2022-06-14 14:30:19,140] Train: Loss: 2.727 | Acc: 41.478 (531402/1281167) | Lr: 0.5992228603537487
[2022-06-14 14:31:11,052] Test: Loss: 2.586 | Acc: 42.580 (21290/50000)
[2022-06-14 14:31:11,052] Saving..
[2022-06-14 14:31:11,130] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 14:31:11,130] Epoch: 12
[2022-06-14 14:48:59,977] Train: Loss: 2.700 | Acc: 41.884 (536600/1281167) | Lr: 0.5990752155332696
[2022-06-14 14:49:49,273] Test: Loss: 2.696 | Acc: 40.994 (20497/50000)
[2022-06-14 14:49:49,273] Epoch: 13
[2022-06-14 15:07:52,424] Train: Loss: 2.673 | Acc: 42.454 (543902/1281167) | Lr: 0.5989147595401398
[2022-06-14 15:08:45,236] Test: Loss: 2.715 | Acc: 39.934 (19967/50000)
[2022-06-14 15:08:45,236] Epoch: 14
[2022-06-14 15:26:38,286] Train: Loss: 2.654 | Acc: 42.758 (547799/1281167) | Lr: 0.5987414992477603
[2022-06-14 15:27:27,230] Test: Loss: 2.731 | Acc: 40.242 (20121/50000)
[2022-06-14 15:27:27,231] Epoch: 15
[2022-06-14 15:45:19,533] Train: Loss: 2.639 | Acc: 43.019 (551144/1281167) | Lr: 0.5985554420780254
[2022-06-14 15:46:08,054] Test: Loss: 2.555 | Acc: 43.490 (21745/50000)
[2022-06-14 15:46:08,055] Saving..
[2022-06-14 15:46:08,167] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 15:46:08,167] Epoch: 16
[2022-06-14 16:04:04,897] Train: Loss: 2.622 | Acc: 43.267 (554322/1281167) | Lr: 0.5983565960010048
[2022-06-14 16:04:52,582] Test: Loss: 2.567 | Acc: 43.300 (21650/50000)
[2022-06-14 16:04:52,582] Epoch: 17
[2022-06-14 16:22:54,936] Train: Loss: 2.607 | Acc: 43.565 (558141/1281167) | Lr: 0.5981449695346027
[2022-06-14 16:23:46,142] Test: Loss: 2.459 | Acc: 44.758 (22379/50000)
[2022-06-14 16:23:46,142] Saving..
[2022-06-14 16:23:46,293] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 16:23:46,293] Epoch: 18
[2022-06-14 16:41:42,596] Train: Loss: 2.593 | Acc: 43.824 (561455/1281167) | Lr: 0.5979205717441928
[2022-06-14 16:42:30,372] Test: Loss: 2.325 | Acc: 46.986 (23493/50000)
[2022-06-14 16:42:30,373] Saving..
[2022-06-14 16:42:30,476] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 16:42:30,476] Epoch: 19
[2022-06-14 17:00:30,097] Train: Loss: 2.582 | Acc: 44.014 (563898/1281167) | Lr: 0.5976834122422292
[2022-06-14 17:01:18,555] Test: Loss: 2.352 | Acc: 46.190 (23095/50000)
[2022-06-14 17:01:18,555] Epoch: 20
[2022-06-14 17:19:17,047] Train: Loss: 2.573 | Acc: 44.172 (565921/1281167) | Lr: 0.5974335011878359
[2022-06-14 17:20:04,783] Test: Loss: 2.445 | Acc: 44.948 (22474/50000)
[2022-06-14 17:20:04,784] Epoch: 21
[2022-06-14 17:38:00,359] Train: Loss: 2.561 | Acc: 44.351 (568213/1281167) | Lr: 0.5971708492863705
[2022-06-14 17:38:48,513] Test: Loss: 2.539 | Acc: 43.668 (21834/50000)
[2022-06-14 17:38:48,513] Epoch: 22
[2022-06-14 17:56:33,517] Train: Loss: 2.552 | Acc: 44.487 (569947/1281167) | Lr: 0.5968954677889666
[2022-06-14 17:57:21,304] Test: Loss: 2.530 | Acc: 43.840 (21920/50000)
[2022-06-14 17:57:21,304] Epoch: 23
[2022-06-14 18:15:19,542] Train: Loss: 2.544 | Acc: 44.684 (572472/1281167) | Lr: 0.5966073684920506
[2022-06-14 18:16:08,174] Test: Loss: 2.780 | Acc: 39.116 (19558/50000)
[2022-06-14 18:16:08,174] Epoch: 24
[2022-06-14 18:34:08,703] Train: Loss: 2.538 | Acc: 44.852 (574629/1281167) | Lr: 0.596306563736838
[2022-06-14 18:34:56,132] Test: Loss: 2.296 | Acc: 47.810 (23905/50000)
[2022-06-14 18:34:56,133] Saving..
[2022-06-14 18:34:56,219] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 18:34:56,219] Epoch: 25
[2022-06-14 18:52:55,895] Train: Loss: 2.525 | Acc: 45.013 (576696/1281167) | Lr: 0.5959930664088029
[2022-06-14 18:53:45,161] Test: Loss: 2.671 | Acc: 41.642 (20821/50000)
[2022-06-14 18:53:45,161] Epoch: 26
[2022-06-14 19:11:41,892] Train: Loss: 2.520 | Acc: 45.074 (577470/1281167) | Lr: 0.5956668899371277
[2022-06-14 19:12:36,356] Test: Loss: 2.402 | Acc: 46.194 (23097/50000)
[2022-06-14 19:12:36,357] Epoch: 27
[2022-06-14 19:30:24,219] Train: Loss: 2.515 | Acc: 45.199 (579073/1281167) | Lr: 0.5953280482941267
[2022-06-14 19:31:13,609] Test: Loss: 2.304 | Acc: 47.932 (23966/50000)
[2022-06-14 19:31:13,609] Saving..
[2022-06-14 19:31:13,699] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 19:31:13,700] Epoch: 28
[2022-06-14 19:49:11,257] Train: Loss: 2.508 | Acc: 45.298 (580345/1281167) | Lr: 0.5949765559946483
[2022-06-14 19:49:59,850] Test: Loss: 2.362 | Acc: 46.618 (23309/50000)
[2022-06-14 19:49:59,850] Epoch: 29
[2022-06-14 20:07:47,970] Train: Loss: 2.502 | Acc: 45.416 (581851/1281167) | Lr: 0.5946124280954524
[2022-06-14 20:08:35,420] Test: Loss: 2.239 | Acc: 48.724 (24362/50000)
[2022-06-14 20:08:35,420] Saving..
[2022-06-14 20:08:35,504] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 20:08:35,504] Epoch: 30
[2022-06-14 20:26:21,933] Train: Loss: 2.497 | Acc: 45.538 (583421/1281167) | Lr: 0.5942356801945667
[2022-06-14 20:27:13,629] Test: Loss: 2.306 | Acc: 47.734 (23867/50000)
[2022-06-14 20:27:13,630] Epoch: 31
[2022-06-14 20:45:06,181] Train: Loss: 2.492 | Acc: 45.617 (584426/1281167) | Lr: 0.5938463284306172
[2022-06-14 20:45:53,589] Test: Loss: 2.565 | Acc: 42.502 (21251/50000)
[2022-06-14 20:45:53,590] Epoch: 32
[2022-06-14 21:04:10,934] Train: Loss: 2.490 | Acc: 45.667 (585065/1281167) | Lr: 0.5934443894821377
[2022-06-14 21:04:57,020] Test: Loss: 2.390 | Acc: 46.030 (23015/50000)
[2022-06-14 21:04:57,020] Epoch: 33
[2022-06-14 21:23:02,008] Train: Loss: 2.485 | Acc: 45.714 (585675/1281167) | Lr: 0.5930298805668548
[2022-06-14 21:23:48,907] Test: Loss: 2.537 | Acc: 43.048 (21524/50000)
[2022-06-14 21:23:48,908] Epoch: 34
[2022-06-14 21:41:45,124] Train: Loss: 2.481 | Acc: 45.843 (587331/1281167) | Lr: 0.592602819440951
[2022-06-14 21:42:36,090] Test: Loss: 2.942 | Acc: 38.022 (19011/50000)
[2022-06-14 21:42:36,091] Epoch: 35
[2022-06-14 22:00:28,651] Train: Loss: 2.474 | Acc: 45.928 (588409/1281167) | Lr: 0.5921632243983034
[2022-06-14 22:01:16,440] Test: Loss: 2.190 | Acc: 49.680 (24840/50000)
[2022-06-14 22:01:16,440] Saving..
[2022-06-14 22:01:16,526] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-14 22:01:16,526] Epoch: 36
[2022-06-14 22:19:11,304] Train: Loss: 2.470 | Acc: 45.988 (589178/1281167) | Lr: 0.5917111142697007
[2022-06-14 22:19:59,606] Test: Loss: 2.578 | Acc: 44.082 (22041/50000)
[2022-06-14 22:19:59,606] Epoch: 37
[2022-06-14 22:38:00,029] Train: Loss: 2.464 | Acc: 46.123 (590913/1281167) | Lr: 0.591246508422036
[2022-06-14 22:38:48,931] Test: Loss: 2.332 | Acc: 46.948 (23474/50000)
[2022-06-14 22:38:48,931] Epoch: 38
[2022-06-14 22:56:36,196] Train: Loss: 2.463 | Acc: 46.159 (591378/1281167) | Lr: 0.5907694267574775
[2022-06-14 22:57:24,329] Test: Loss: 2.418 | Acc: 46.248 (23124/50000)
[2022-06-14 22:57:24,329] Epoch: 39
[2022-06-14 23:15:16,552] Train: Loss: 2.462 | Acc: 46.204 (591956/1281167) | Lr: 0.5902798897126158
[2022-06-14 23:16:07,086] Test: Loss: 2.673 | Acc: 42.316 (21158/50000)
[2022-06-14 23:16:07,086] Epoch: 40
[2022-06-14 23:34:05,658] Train: Loss: 2.456 | Acc: 46.310 (593303/1281167) | Lr: 0.5897779182575887
[2022-06-14 23:34:53,744] Test: Loss: 2.446 | Acc: 45.184 (22592/50000)
[2022-06-14 23:34:53,744] Epoch: 41
[2022-06-14 23:52:43,289] Train: Loss: 2.453 | Acc: 46.415 (594653/1281167) | Lr: 0.5892635338951826
[2022-06-14 23:53:31,192] Test: Loss: 2.313 | Acc: 48.234 (24117/50000)
[2022-06-14 23:53:31,192] Epoch: 42
[2022-06-15 00:11:36,638] Train: Loss: 2.451 | Acc: 46.367 (594037/1281167) | Lr: 0.5887367586599115
[2022-06-15 00:12:25,108] Test: Loss: 2.221 | Acc: 49.070 (24535/50000)
[2022-06-15 00:12:25,108] Epoch: 43
[2022-06-15 00:30:27,604] Train: Loss: 2.447 | Acc: 46.417 (594679/1281167) | Lr: 0.5881976151170734
[2022-06-15 00:31:16,527] Test: Loss: 2.199 | Acc: 49.504 (24752/50000)
[2022-06-15 00:31:16,527] Epoch: 44
[2022-06-15 00:49:13,191] Train: Loss: 2.445 | Acc: 46.500 (595739/1281167) | Lr: 0.5876461263617831
[2022-06-15 00:50:02,177] Test: Loss: 2.303 | Acc: 46.896 (23448/50000)
[2022-06-15 00:50:02,177] Epoch: 45
[2022-06-15 01:07:58,377] Train: Loss: 2.444 | Acc: 46.557 (596475/1281167) | Lr: 0.5870823160179836
[2022-06-15 01:08:47,190] Test: Loss: 2.592 | Acc: 43.228 (21614/50000)
[2022-06-15 01:08:47,190] Epoch: 46
[2022-06-15 01:26:49,904] Train: Loss: 2.439 | Acc: 46.644 (597586/1281167) | Lr: 0.5865062082374333
[2022-06-15 01:27:38,068] Test: Loss: 2.792 | Acc: 40.764 (20382/50000)
[2022-06-15 01:27:38,069] Epoch: 47
[2022-06-15 01:45:35,230] Train: Loss: 2.441 | Acc: 46.598 (596998/1281167) | Lr: 0.5859178276986722
[2022-06-15 01:46:23,724] Test: Loss: 2.128 | Acc: 50.688 (25344/50000)
[2022-06-15 01:46:23,724] Saving..
[2022-06-15 01:46:23,819] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 01:46:23,819] Epoch: 48
[2022-06-15 02:04:13,759] Train: Loss: 2.433 | Acc: 46.737 (598783/1281167) | Lr: 0.5853171996059642
[2022-06-15 02:05:02,335] Test: Loss: 2.374 | Acc: 46.308 (23154/50000)
[2022-06-15 02:05:02,336] Epoch: 49
[2022-06-15 02:23:04,186] Train: Loss: 2.431 | Acc: 46.785 (599391/1281167) | Lr: 0.5847043496882178
[2022-06-15 02:23:51,830] Test: Loss: 2.502 | Acc: 44.516 (22258/50000)
[2022-06-15 02:23:51,831] Epoch: 50
[2022-06-15 02:41:50,756] Train: Loss: 2.432 | Acc: 46.718 (598540/1281167) | Lr: 0.5840793041978839
[2022-06-15 02:42:38,909] Test: Loss: 2.851 | Acc: 39.360 (19680/50000)
[2022-06-15 02:42:38,909] Epoch: 51
[2022-06-15 03:00:28,314] Train: Loss: 2.423 | Acc: 46.949 (601493/1281167) | Lr: 0.5834420899098308
[2022-06-15 03:01:16,779] Test: Loss: 2.623 | Acc: 42.766 (21383/50000)
[2022-06-15 03:01:16,779] Epoch: 52
[2022-06-15 03:19:06,897] Train: Loss: 2.430 | Acc: 46.772 (599233/1281167) | Lr: 0.5827927341201978
[2022-06-15 03:19:57,168] Test: Loss: 2.204 | Acc: 49.634 (24817/50000)
[2022-06-15 03:19:57,168] Epoch: 53
[2022-06-15 03:37:56,842] Train: Loss: 2.418 | Acc: 46.922 (601147/1281167) | Lr: 0.5821312646452258
[2022-06-15 03:38:44,881] Test: Loss: 2.151 | Acc: 50.180 (25090/50000)
[2022-06-15 03:38:44,881] Epoch: 54
[2022-06-15 03:56:49,901] Train: Loss: 2.420 | Acc: 47.009 (602262/1281167) | Lr: 0.5814577098200655
[2022-06-15 03:57:37,064] Test: Loss: 3.237 | Acc: 33.896 (16948/50000)
[2022-06-15 03:57:37,064] Epoch: 55
[2022-06-15 04:15:26,004] Train: Loss: 2.421 | Acc: 46.970 (601770/1281167) | Lr: 0.5807720984975637
[2022-06-15 04:16:13,934] Test: Loss: 2.294 | Acc: 47.200 (23600/50000)
[2022-06-15 04:16:13,934] Epoch: 56
[2022-06-15 04:34:18,399] Train: Loss: 2.416 | Acc: 47.064 (602970/1281167) | Lr: 0.5800744600470279
[2022-06-15 04:35:11,554] Test: Loss: 2.550 | Acc: 43.658 (21829/50000)
[2022-06-15 04:35:11,555] Epoch: 57
[2022-06-15 04:53:12,656] Train: Loss: 2.415 | Acc: 47.047 (602747/1281167) | Lr: 0.5793648243529671
[2022-06-15 04:54:02,024] Test: Loss: 2.567 | Acc: 43.992 (21996/50000)
[2022-06-15 04:54:02,025] Epoch: 58
[2022-06-15 05:12:03,114] Train: Loss: 2.414 | Acc: 47.084 (603223/1281167) | Lr: 0.5786432218138128
[2022-06-15 05:12:52,129] Test: Loss: 2.937 | Acc: 39.476 (19738/50000)
[2022-06-15 05:12:52,129] Epoch: 59
[2022-06-15 05:30:55,936] Train: Loss: 2.412 | Acc: 47.080 (603172/1281167) | Lr: 0.5779096833406159
[2022-06-15 05:31:43,813] Test: Loss: 2.451 | Acc: 45.424 (22712/50000)
[2022-06-15 05:31:43,813] Epoch: 60
[2022-06-15 05:49:34,355] Train: Loss: 2.411 | Acc: 47.100 (603427/1281167) | Lr: 0.5771642403557232
[2022-06-15 05:50:22,284] Test: Loss: 2.215 | Acc: 49.124 (24562/50000)
[2022-06-15 05:50:22,284] Epoch: 61
[2022-06-15 06:08:15,966] Train: Loss: 2.405 | Acc: 47.251 (605369/1281167) | Lr: 0.5764069247914314
[2022-06-15 06:09:05,173] Test: Loss: 2.582 | Acc: 43.884 (21942/50000)
[2022-06-15 06:09:05,173] Epoch: 62
[2022-06-15 06:26:58,557] Train: Loss: 2.409 | Acc: 47.178 (604435/1281167) | Lr: 0.5756377690886185
[2022-06-15 06:27:46,115] Test: Loss: 2.208 | Acc: 49.058 (24529/50000)
[2022-06-15 06:27:46,116] Epoch: 63
[2022-06-15 06:45:38,563] Train: Loss: 2.403 | Acc: 47.227 (605052/1281167) | Lr: 0.574856806195355
[2022-06-15 06:46:26,955] Test: Loss: 2.481 | Acc: 44.560 (22280/50000)
[2022-06-15 06:46:26,955] Epoch: 64
[2022-06-15 07:04:28,247] Train: Loss: 2.405 | Acc: 47.216 (604910/1281167) | Lr: 0.5740640695654917
[2022-06-15 07:05:16,394] Test: Loss: 2.202 | Acc: 49.416 (24708/50000)
[2022-06-15 07:05:16,394] Epoch: 65
[2022-06-15 07:23:10,913] Train: Loss: 2.400 | Acc: 47.303 (606025/1281167) | Lr: 0.5732595931572279
[2022-06-15 07:24:02,472] Test: Loss: 2.134 | Acc: 51.098 (25549/50000)
[2022-06-15 07:24:02,472] Saving..
[2022-06-15 07:24:02,551] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 07:24:02,551] Epoch: 66
[2022-06-15 07:41:46,304] Train: Loss: 2.398 | Acc: 47.323 (606284/1281167) | Lr: 0.572443411431655
[2022-06-15 07:42:35,513] Test: Loss: 2.641 | Acc: 42.390 (21195/50000)
[2022-06-15 07:42:35,513] Epoch: 67
[2022-06-15 08:00:28,857] Train: Loss: 2.399 | Acc: 47.352 (606658/1281167) | Lr: 0.5716155593512818
[2022-06-15 08:01:17,584] Test: Loss: 2.138 | Acc: 50.622 (25311/50000)
[2022-06-15 08:01:17,584] Epoch: 68
[2022-06-15 08:19:13,847] Train: Loss: 2.395 | Acc: 47.434 (607715/1281167) | Lr: 0.5707760723785362
[2022-06-15 08:20:02,007] Test: Loss: 2.204 | Acc: 49.516 (24758/50000)
[2022-06-15 08:20:02,007] Epoch: 69
[2022-06-15 08:38:03,568] Train: Loss: 2.395 | Acc: 47.414 (607453/1281167) | Lr: 0.5699249864742459
[2022-06-15 08:38:55,012] Test: Loss: 2.533 | Acc: 44.068 (22034/50000)
[2022-06-15 08:38:55,013] Epoch: 70
[2022-06-15 08:57:07,285] Train: Loss: 2.393 | Acc: 47.422 (607551/1281167) | Lr: 0.5690623380960986
[2022-06-15 08:57:55,490] Test: Loss: 2.354 | Acc: 46.858 (23429/50000)
[2022-06-15 08:57:55,491] Epoch: 71
[2022-06-15 09:15:42,742] Train: Loss: 2.391 | Acc: 47.415 (607470/1281167) | Lr: 0.5681881641970796
[2022-06-15 09:16:30,653] Test: Loss: 2.288 | Acc: 47.948 (23974/50000)
[2022-06-15 09:16:30,653] Epoch: 72
[2022-06-15 09:34:31,849] Train: Loss: 2.392 | Acc: 47.468 (608143/1281167) | Lr: 0.5673025022238892
[2022-06-15 09:35:19,841] Test: Loss: 2.386 | Acc: 46.598 (23299/50000)
[2022-06-15 09:35:19,842] Epoch: 73
[2022-06-15 09:53:16,735] Train: Loss: 2.392 | Acc: 47.483 (608336/1281167) | Lr: 0.5664053901153387
[2022-06-15 09:54:04,697] Test: Loss: 2.322 | Acc: 47.582 (23791/50000)
[2022-06-15 09:54:04,698] Epoch: 74
[2022-06-15 10:11:55,813] Train: Loss: 2.389 | Acc: 47.576 (609534/1281167) | Lr: 0.565496866300725
[2022-06-15 10:12:44,064] Test: Loss: 2.724 | Acc: 41.012 (20506/50000)
[2022-06-15 10:12:44,064] Epoch: 75
[2022-06-15 10:30:39,959] Train: Loss: 2.386 | Acc: 47.535 (608999/1281167) | Lr: 0.5645769696981845
[2022-06-15 10:31:28,348] Test: Loss: 2.366 | Acc: 46.820 (23410/50000)
[2022-06-15 10:31:28,349] Epoch: 76
[2022-06-15 10:49:19,019] Train: Loss: 2.382 | Acc: 47.622 (610115/1281167) | Lr: 0.563645739713026
[2022-06-15 10:50:06,694] Test: Loss: 2.313 | Acc: 47.420 (23710/50000)
[2022-06-15 10:50:06,694] Epoch: 77
[2022-06-15 11:07:59,880] Train: Loss: 2.382 | Acc: 47.669 (610714/1281167) | Lr: 0.5627032162360428
[2022-06-15 11:08:48,323] Test: Loss: 2.237 | Acc: 48.920 (24460/50000)
[2022-06-15 11:08:48,324] Epoch: 78
[2022-06-15 11:26:51,513] Train: Loss: 2.385 | Acc: 47.642 (610373/1281167) | Lr: 0.5617494396418036
[2022-06-15 11:27:40,902] Test: Loss: 2.443 | Acc: 45.128 (22564/50000)
[2022-06-15 11:27:40,902] Epoch: 79
[2022-06-15 11:45:43,917] Train: Loss: 2.378 | Acc: 47.730 (611503/1281167) | Lr: 0.5607844507869232
[2022-06-15 11:46:31,765] Test: Loss: 2.286 | Acc: 48.096 (24048/50000)
[2022-06-15 11:46:31,765] Epoch: 80
[2022-06-15 12:04:24,646] Train: Loss: 2.380 | Acc: 47.652 (610507/1281167) | Lr: 0.5598082910083125
[2022-06-15 12:05:12,341] Test: Loss: 2.467 | Acc: 45.582 (22791/50000)
[2022-06-15 12:05:12,341] Epoch: 81
[2022-06-15 12:23:03,101] Train: Loss: 2.377 | Acc: 47.748 (611736/1281167) | Lr: 0.5588210021214074
[2022-06-15 12:23:51,070] Test: Loss: 2.556 | Acc: 44.808 (22404/50000)
[2022-06-15 12:23:51,070] Epoch: 82
[2022-06-15 12:41:36,226] Train: Loss: 2.377 | Acc: 47.739 (611617/1281167) | Lr: 0.5578226264183781
[2022-06-15 12:42:24,448] Test: Loss: 2.083 | Acc: 51.596 (25798/50000)
[2022-06-15 12:42:24,448] Saving..
[2022-06-15 12:42:24,529] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 12:42:24,529] Epoch: 83
[2022-06-15 13:00:19,415] Train: Loss: 2.373 | Acc: 47.805 (612468/1281167) | Lr: 0.5568132066663166
[2022-06-15 13:01:07,593] Test: Loss: 2.165 | Acc: 50.302 (25151/50000)
[2022-06-15 13:01:07,594] Epoch: 84
[2022-06-15 13:19:05,908] Train: Loss: 2.373 | Acc: 47.811 (612534/1281167) | Lr: 0.5557927861054056
[2022-06-15 13:19:53,309] Test: Loss: 2.862 | Acc: 39.980 (19990/50000)
[2022-06-15 13:19:53,309] Epoch: 85
[2022-06-15 13:37:56,746] Train: Loss: 2.369 | Acc: 47.913 (613849/1281167) | Lr: 0.5547614084470658
[2022-06-15 13:38:45,229] Test: Loss: 2.192 | Acc: 49.610 (24805/50000)
[2022-06-15 13:38:45,229] Epoch: 86
[2022-06-15 13:56:42,026] Train: Loss: 2.369 | Acc: 47.914 (613855/1281167) | Lr: 0.5537191178720833
[2022-06-15 13:57:35,446] Test: Loss: 2.284 | Acc: 47.906 (23953/50000)
[2022-06-15 13:57:35,446] Epoch: 87
[2022-06-15 14:15:24,972] Train: Loss: 2.367 | Acc: 47.956 (614399/1281167) | Lr: 0.5526659590287172
[2022-06-15 14:16:12,920] Test: Loss: 2.017 | Acc: 52.840 (26420/50000)
[2022-06-15 14:16:12,920] Saving..
[2022-06-15 14:16:13,004] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 14:16:13,004] Epoch: 88
[2022-06-15 14:34:11,567] Train: Loss: 2.367 | Acc: 47.930 (614061/1281167) | Lr: 0.5516019770307873
[2022-06-15 14:34:58,598] Test: Loss: 2.134 | Acc: 50.598 (25299/50000)
[2022-06-15 14:34:58,598] Epoch: 89
[2022-06-15 14:52:49,322] Train: Loss: 2.366 | Acc: 47.983 (614742/1281167) | Lr: 0.5505272174557411
[2022-06-15 14:53:37,473] Test: Loss: 2.264 | Acc: 48.966 (24483/50000)
[2022-06-15 14:53:37,474] Epoch: 90
[2022-06-15 15:11:31,139] Train: Loss: 2.361 | Acc: 48.020 (615221/1281167) | Lr: 0.5494417263427018
[2022-06-15 15:12:19,456] Test: Loss: 3.087 | Acc: 35.748 (17874/50000)
[2022-06-15 15:12:19,456] Epoch: 91
[2022-06-15 15:30:13,952] Train: Loss: 2.362 | Acc: 48.011 (615103/1281167) | Lr: 0.5483455501904958
[2022-06-15 15:31:02,145] Test: Loss: 2.299 | Acc: 48.014 (24007/50000)
[2022-06-15 15:31:02,146] Epoch: 92
[2022-06-15 15:48:45,019] Train: Loss: 2.361 | Acc: 48.068 (615831/1281167) | Lr: 0.5472387359556613
[2022-06-15 15:49:32,572] Test: Loss: 2.297 | Acc: 47.696 (23848/50000)
[2022-06-15 15:49:32,572] Epoch: 93
[2022-06-15 16:07:15,858] Train: Loss: 2.364 | Acc: 47.993 (614870/1281167) | Lr: 0.5461213310504361
[2022-06-15 16:08:05,441] Test: Loss: 2.124 | Acc: 51.290 (25645/50000)
[2022-06-15 16:08:05,442] Epoch: 94
[2022-06-15 16:25:53,818] Train: Loss: 2.361 | Acc: 48.022 (615242/1281167) | Lr: 0.5449933833407276
[2022-06-15 16:26:41,831] Test: Loss: 2.761 | Acc: 40.736 (20368/50000)
[2022-06-15 16:26:41,831] Epoch: 95
[2022-06-15 16:44:36,623] Train: Loss: 2.355 | Acc: 48.125 (616566/1281167) | Lr: 0.5438549411440613
[2022-06-15 16:45:24,966] Test: Loss: 2.244 | Acc: 48.396 (24198/50000)
[2022-06-15 16:45:24,967] Epoch: 96
[2022-06-15 17:03:08,977] Train: Loss: 2.353 | Acc: 48.201 (617530/1281167) | Lr: 0.542706053227512
[2022-06-15 17:03:57,343] Test: Loss: 2.101 | Acc: 51.062 (25531/50000)
[2022-06-15 17:03:57,343] Epoch: 97
[2022-06-15 17:21:47,356] Train: Loss: 2.352 | Acc: 48.196 (617466/1281167) | Lr: 0.5415467688056143
[2022-06-15 17:22:36,224] Test: Loss: 2.144 | Acc: 50.714 (25357/50000)
[2022-06-15 17:22:36,225] Epoch: 98
[2022-06-15 17:40:29,572] Train: Loss: 2.355 | Acc: 48.136 (616703/1281167) | Lr: 0.5403771375382543
[2022-06-15 17:41:18,514] Test: Loss: 2.099 | Acc: 51.654 (25827/50000)
[2022-06-15 17:41:18,515] Epoch: 99
[2022-06-15 17:59:06,254] Train: Loss: 2.351 | Acc: 48.234 (617963/1281167) | Lr: 0.5391972095285429
[2022-06-15 17:59:54,803] Test: Loss: 2.042 | Acc: 52.198 (26099/50000)
[2022-06-15 17:59:54,804] Epoch: 100
[2022-06-15 18:17:37,116] Train: Loss: 2.346 | Acc: 48.322 (619089/1281167) | Lr: 0.5380070353206687
[2022-06-15 18:18:26,684] Test: Loss: 2.269 | Acc: 48.372 (24186/50000)
[2022-06-15 18:18:26,685] Epoch: 101
[2022-06-15 18:36:18,770] Train: Loss: 2.346 | Acc: 48.283 (618581/1281167) | Lr: 0.5368066658977336
[2022-06-15 18:37:07,370] Test: Loss: 2.834 | Acc: 40.274 (20137/50000)
[2022-06-15 18:37:07,370] Epoch: 102
[2022-06-15 18:54:45,374] Train: Loss: 2.344 | Acc: 48.380 (619835/1281167) | Lr: 0.5355961526795687
[2022-06-15 18:55:34,974] Test: Loss: 2.016 | Acc: 53.042 (26521/50000)
[2022-06-15 18:55:34,974] Saving..
[2022-06-15 18:55:35,070] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 18:55:35,070] Epoch: 103
[2022-06-15 19:13:11,207] Train: Loss: 2.346 | Acc: 48.326 (619141/1281167) | Lr: 0.5343755475205313
[2022-06-15 19:14:00,830] Test: Loss: 2.144 | Acc: 50.500 (25250/50000)
[2022-06-15 19:14:00,831] Epoch: 104
[2022-06-15 19:31:39,856] Train: Loss: 2.341 | Acc: 48.434 (620520/1281167) | Lr: 0.5331449027072837
[2022-06-15 19:32:28,434] Test: Loss: 2.052 | Acc: 52.328 (26164/50000)
[2022-06-15 19:32:28,434] Epoch: 105
[2022-06-15 19:50:10,801] Train: Loss: 2.339 | Acc: 48.446 (620677/1281167) | Lr: 0.5319042709565539
[2022-06-15 19:50:59,474] Test: Loss: 2.359 | Acc: 47.416 (23708/50000)
[2022-06-15 19:50:59,474] Epoch: 106
[2022-06-15 20:08:47,184] Train: Loss: 2.343 | Acc: 48.420 (620342/1281167) | Lr: 0.5306537054128772
[2022-06-15 20:09:36,476] Test: Loss: 2.249 | Acc: 48.984 (24492/50000)
[2022-06-15 20:09:36,477] Epoch: 107
[2022-06-15 20:27:20,613] Train: Loss: 2.338 | Acc: 48.433 (620512/1281167) | Lr: 0.529393259646319
[2022-06-15 20:28:09,546] Test: Loss: 2.453 | Acc: 45.590 (22795/50000)
[2022-06-15 20:28:09,546] Epoch: 108
[2022-06-15 20:45:46,719] Train: Loss: 2.337 | Acc: 48.485 (621168/1281167) | Lr: 0.528122987650181
[2022-06-15 20:46:35,094] Test: Loss: 2.520 | Acc: 44.320 (22160/50000)
[2022-06-15 20:46:35,094] Epoch: 109
[2022-06-15 21:04:17,773] Train: Loss: 2.334 | Acc: 48.590 (622525/1281167) | Lr: 0.5268429438386876
[2022-06-15 21:05:06,374] Test: Loss: 2.130 | Acc: 50.586 (25293/50000)
[2022-06-15 21:05:06,374] Epoch: 110
[2022-06-15 21:22:44,342] Train: Loss: 2.336 | Acc: 48.543 (621921/1281167) | Lr: 0.5255531830446555
[2022-06-15 21:23:33,545] Test: Loss: 2.244 | Acc: 49.210 (24605/50000)
[2022-06-15 21:23:33,546] Epoch: 111
[2022-06-15 21:41:11,176] Train: Loss: 2.335 | Acc: 48.528 (621729/1281167) | Lr: 0.5242537605171443
[2022-06-15 21:42:00,560] Test: Loss: 2.129 | Acc: 51.152 (25576/50000)
[2022-06-15 21:42:00,561] Epoch: 112
[2022-06-15 21:59:42,798] Train: Loss: 2.330 | Acc: 48.629 (623025/1281167) | Lr: 0.5229447319190905
[2022-06-15 22:00:31,463] Test: Loss: 2.027 | Acc: 52.838 (26419/50000)
[2022-06-15 22:00:31,463] Epoch: 113
[2022-06-15 22:18:09,042] Train: Loss: 2.329 | Acc: 48.692 (623824/1281167) | Lr: 0.5216261533249222
[2022-06-15 22:18:57,529] Test: Loss: 2.133 | Acc: 50.636 (25318/50000)
[2022-06-15 22:18:57,529] Epoch: 114
[2022-06-15 22:36:35,995] Train: Loss: 2.329 | Acc: 48.682 (623703/1281167) | Lr: 0.5202980812181581
[2022-06-15 22:37:24,971] Test: Loss: 2.032 | Acc: 52.632 (26316/50000)
[2022-06-15 22:37:24,971] Epoch: 115
[2022-06-15 22:55:01,732] Train: Loss: 2.324 | Acc: 48.690 (623796/1281167) | Lr: 0.5189605724889867
[2022-06-15 22:55:49,796] Test: Loss: 2.413 | Acc: 45.646 (22823/50000)
[2022-06-15 22:55:49,796] Epoch: 116
[2022-06-15 23:13:30,021] Train: Loss: 2.327 | Acc: 48.723 (624218/1281167) | Lr: 0.5176136844318308
[2022-06-15 23:14:18,366] Test: Loss: 2.008 | Acc: 53.468 (26734/50000)
[2022-06-15 23:14:18,366] Saving..
[2022-06-15 23:14:18,465] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-15 23:14:18,465] Epoch: 117
[2022-06-15 23:31:58,712] Train: Loss: 2.327 | Acc: 48.667 (623510/1281167) | Lr: 0.5162574747428917
[2022-06-15 23:32:46,499] Test: Loss: 2.042 | Acc: 52.742 (26371/50000)
[2022-06-15 23:32:46,500] Epoch: 118
[2022-06-15 23:50:18,968] Train: Loss: 2.322 | Acc: 48.736 (624394/1281167) | Lr: 0.5148920015176788
[2022-06-15 23:51:06,469] Test: Loss: 2.089 | Acc: 51.428 (25714/50000)
[2022-06-15 23:51:06,469] Epoch: 119
[2022-06-16 00:08:45,551] Train: Loss: 2.322 | Acc: 48.750 (624567/1281167) | Lr: 0.5135173232485203
[2022-06-16 00:09:34,553] Test: Loss: 2.070 | Acc: 51.842 (25921/50000)
[2022-06-16 00:09:34,554] Epoch: 120
[2022-06-16 00:27:12,590] Train: Loss: 2.320 | Acc: 48.801 (625216/1281167) | Lr: 0.5121334988220579
[2022-06-16 00:28:01,208] Test: Loss: 2.110 | Acc: 51.422 (25711/50000)
[2022-06-16 00:28:01,208] Epoch: 121
[2022-06-16 00:45:47,668] Train: Loss: 2.317 | Acc: 48.912 (626639/1281167) | Lr: 0.5107405875167246
[2022-06-16 00:46:35,377] Test: Loss: 2.083 | Acc: 51.686 (25843/50000)
[2022-06-16 00:46:35,377] Epoch: 122
[2022-06-16 01:04:15,852] Train: Loss: 2.318 | Acc: 48.867 (626070/1281167) | Lr: 0.5093386490002044
[2022-06-16 01:05:04,700] Test: Loss: 2.779 | Acc: 40.670 (20335/50000)
[2022-06-16 01:05:04,700] Epoch: 123
[2022-06-16 01:22:39,237] Train: Loss: 2.319 | Acc: 48.909 (626606/1281167) | Lr: 0.5079277433268776
[2022-06-16 01:23:26,678] Test: Loss: 2.164 | Acc: 50.210 (25105/50000)
[2022-06-16 01:23:26,678] Epoch: 124
[2022-06-16 01:41:03,148] Train: Loss: 2.315 | Acc: 48.924 (626799/1281167) | Lr: 0.5065079309352473
[2022-06-16 01:41:51,404] Test: Loss: 2.026 | Acc: 52.848 (26424/50000)
[2022-06-16 01:41:51,405] Epoch: 125
[2022-06-16 01:59:30,090] Train: Loss: 2.313 | Acc: 48.944 (627056/1281167) | Lr: 0.5050792726453508
[2022-06-16 02:00:18,993] Test: Loss: 2.870 | Acc: 39.224 (19612/50000)
[2022-06-16 02:00:18,993] Epoch: 126
[2022-06-16 02:17:56,639] Train: Loss: 2.316 | Acc: 48.877 (626190/1281167) | Lr: 0.5036418296561543
[2022-06-16 02:18:44,901] Test: Loss: 2.119 | Acc: 51.562 (25781/50000)
[2022-06-16 02:18:44,902] Epoch: 127
[2022-06-16 02:36:24,365] Train: Loss: 2.308 | Acc: 49.066 (628616/1281167) | Lr: 0.5021956635429314
[2022-06-16 02:37:12,997] Test: Loss: 2.962 | Acc: 37.596 (18798/50000)
[2022-06-16 02:37:12,997] Epoch: 128
[2022-06-16 02:54:56,684] Train: Loss: 2.306 | Acc: 49.049 (628405/1281167) | Lr: 0.5007408362546251
[2022-06-16 02:55:46,301] Test: Loss: 2.199 | Acc: 50.262 (25131/50000)
[2022-06-16 02:55:46,301] Epoch: 129
[2022-06-16 03:13:25,948] Train: Loss: 2.309 | Acc: 48.971 (627404/1281167) | Lr: 0.4992774101111944
[2022-06-16 03:14:14,509] Test: Loss: 2.164 | Acc: 50.728 (25364/50000)
[2022-06-16 03:14:14,509] Epoch: 130
[2022-06-16 03:31:52,526] Train: Loss: 2.305 | Acc: 49.064 (628595/1281167) | Lr: 0.4978054478009446
[2022-06-16 03:32:39,999] Test: Loss: 1.968 | Acc: 54.196 (27098/50000)
[2022-06-16 03:32:39,999] Saving..
[2022-06-16 03:32:40,088] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-16 03:32:40,088] Epoch: 131
[2022-06-16 03:50:28,381] Train: Loss: 2.302 | Acc: 49.164 (629875/1281167) | Lr: 0.49632501237784193
[2022-06-16 03:51:17,124] Test: Loss: 2.173 | Acc: 50.162 (25081/50000)
[2022-06-16 03:51:17,125] Epoch: 132
[2022-06-16 04:09:48,506] Train: Loss: 2.302 | Acc: 49.169 (629932/1281167) | Lr: 0.49483616725881285
[2022-06-16 04:10:42,608] Test: Loss: 2.423 | Acc: 46.600 (23300/50000)
[2022-06-16 04:10:42,608] Epoch: 133
[2022-06-16 04:28:55,546] Train: Loss: 2.296 | Acc: 49.256 (631053/1281167) | Lr: 0.49333897622102685
[2022-06-16 04:29:43,266] Test: Loss: 2.321 | Acc: 48.132 (24066/50000)
[2022-06-16 04:29:43,267] Epoch: 134
[2022-06-16 04:47:58,839] Train: Loss: 2.303 | Acc: 49.081 (628815/1281167) | Lr: 0.49183350339916493
[2022-06-16 04:48:48,579] Test: Loss: 2.148 | Acc: 50.044 (25022/50000)
[2022-06-16 04:48:48,580] Epoch: 135
[2022-06-16 05:07:00,617] Train: Loss: 2.297 | Acc: 49.253 (631018/1281167) | Lr: 0.4903198132826722
[2022-06-16 05:07:50,051] Test: Loss: 2.030 | Acc: 52.810 (26405/50000)
[2022-06-16 05:07:50,051] Epoch: 136
[2022-06-16 05:26:26,253] Train: Loss: 2.296 | Acc: 49.235 (630779/1281167) | Lr: 0.4887979707129954
[2022-06-16 05:27:14,372] Test: Loss: 2.020 | Acc: 52.960 (26480/50000)
[2022-06-16 05:27:14,373] Epoch: 137
[2022-06-16 05:45:24,194] Train: Loss: 2.299 | Acc: 49.170 (629947/1281167) | Lr: 0.487268040880805
[2022-06-16 05:46:12,638] Test: Loss: 2.265 | Acc: 48.558 (24279/50000)
[2022-06-16 05:46:12,639] Epoch: 138
[2022-06-16 06:04:31,156] Train: Loss: 2.296 | Acc: 49.288 (631465/1281167) | Lr: 0.485730089323203
[2022-06-16 06:05:19,540] Test: Loss: 2.083 | Acc: 51.658 (25829/50000)
[2022-06-16 06:05:19,541] Epoch: 139
[2022-06-16 06:23:35,218] Train: Loss: 2.290 | Acc: 49.390 (632765/1281167) | Lr: 0.48418418192091556
[2022-06-16 06:24:23,696] Test: Loss: 2.516 | Acc: 44.774 (22387/50000)
[2022-06-16 06:24:23,696] Epoch: 140
[2022-06-16 06:42:34,484] Train: Loss: 2.290 | Acc: 49.447 (633503/1281167) | Lr: 0.48263038489547055
[2022-06-16 06:43:24,000] Test: Loss: 2.209 | Acc: 49.616 (24808/50000)
[2022-06-16 06:43:24,001] Epoch: 141
[2022-06-16 07:01:35,503] Train: Loss: 2.289 | Acc: 49.426 (633227/1281167) | Lr: 0.48106876480636107
[2022-06-16 07:02:24,989] Test: Loss: 2.498 | Acc: 44.818 (22409/50000)
[2022-06-16 07:02:24,990] Epoch: 142
[2022-06-16 07:20:31,074] Train: Loss: 2.287 | Acc: 49.392 (632793/1281167) | Lr: 0.47949938854819424
[2022-06-16 07:21:19,222] Test: Loss: 2.194 | Acc: 49.774 (24887/50000)
[2022-06-16 07:21:19,223] Epoch: 143
[2022-06-16 07:39:40,858] Train: Loss: 2.290 | Acc: 49.396 (632848/1281167) | Lr: 0.47792232334782575
[2022-06-16 07:40:31,659] Test: Loss: 2.338 | Acc: 47.684 (23842/50000)
[2022-06-16 07:40:31,660] Epoch: 144
[2022-06-16 07:58:46,801] Train: Loss: 2.290 | Acc: 49.366 (632462/1281167) | Lr: 0.47633763676147983
[2022-06-16 07:59:34,934] Test: Loss: 2.117 | Acc: 51.060 (25530/50000)
[2022-06-16 07:59:34,934] Epoch: 145
[2022-06-16 08:17:49,531] Train: Loss: 2.283 | Acc: 49.520 (634438/1281167) | Lr: 0.47474539667185567
[2022-06-16 08:18:54,200] Test: Loss: 2.072 | Acc: 52.200 (26100/50000)
[2022-06-16 08:18:54,201] Epoch: 146
[2022-06-16 08:37:08,970] Train: Loss: 2.279 | Acc: 49.572 (635095/1281167) | Lr: 0.4731456712852192
[2022-06-16 08:37:56,848] Test: Loss: 3.331 | Acc: 33.924 (16962/50000)
[2022-06-16 08:37:56,848] Epoch: 147
[2022-06-16 08:56:12,531] Train: Loss: 2.281 | Acc: 49.558 (634922/1281167) | Lr: 0.47153852912848176
[2022-06-16 08:57:00,695] Test: Loss: 2.083 | Acc: 51.996 (25998/50000)
[2022-06-16 08:57:00,696] Epoch: 148
[2022-06-16 09:15:12,525] Train: Loss: 2.275 | Acc: 49.653 (636137/1281167) | Lr: 0.4699240390462645
[2022-06-16 09:16:00,921] Test: Loss: 2.238 | Acc: 49.826 (24913/50000)
[2022-06-16 09:16:00,921] Epoch: 149
[2022-06-16 09:34:31,677] Train: Loss: 2.272 | Acc: 49.740 (637255/1281167) | Lr: 0.4683022701979489
[2022-06-16 09:35:20,900] Test: Loss: 2.184 | Acc: 49.934 (24967/50000)
[2022-06-16 09:35:20,900] Epoch: 150
[2022-06-16 09:53:36,164] Train: Loss: 2.272 | Acc: 49.714 (636913/1281167) | Lr: 0.4666732920547148
[2022-06-16 09:54:24,236] Test: Loss: 2.019 | Acc: 53.214 (26607/50000)
[2022-06-16 09:54:24,236] Epoch: 151
[2022-06-16 10:12:27,300] Train: Loss: 2.273 | Acc: 49.699 (636726/1281167) | Lr: 0.46503717439656433
[2022-06-16 10:13:19,385] Test: Loss: 2.117 | Acc: 50.976 (25488/50000)
[2022-06-16 10:13:19,385] Epoch: 152
[2022-06-16 10:31:44,026] Train: Loss: 2.272 | Acc: 49.669 (636346/1281167) | Lr: 0.46339398730933234
[2022-06-16 10:32:30,494] Test: Loss: 2.081 | Acc: 51.872 (25936/50000)
[2022-06-16 10:32:30,494] Epoch: 153
[2022-06-16 10:50:37,869] Train: Loss: 2.268 | Acc: 49.772 (637668/1281167) | Lr: 0.46174380118168473
[2022-06-16 10:51:24,662] Test: Loss: 1.890 | Acc: 55.468 (27734/50000)
[2022-06-16 10:51:24,662] Saving..
[2022-06-16 10:51:24,740] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-16 10:51:24,740] Epoch: 154
[2022-06-16 11:09:28,038] Train: Loss: 2.265 | Acc: 49.822 (638305/1281167) | Lr: 0.4600866867021032
[2022-06-16 11:10:14,792] Test: Loss: 1.913 | Acc: 55.044 (27522/50000)
[2022-06-16 11:10:14,792] Epoch: 155
[2022-06-16 11:28:13,704] Train: Loss: 2.263 | Acc: 49.895 (639232/1281167) | Lr: 0.45842271485585645
[2022-06-16 11:29:02,826] Test: Loss: 2.138 | Acc: 51.166 (25583/50000)
[2022-06-16 11:29:02,827] Epoch: 156
[2022-06-16 11:47:02,958] Train: Loss: 2.262 | Acc: 49.917 (639521/1281167) | Lr: 0.45675195692196036
[2022-06-16 11:47:52,926] Test: Loss: 2.012 | Acc: 52.664 (26332/50000)
[2022-06-16 11:47:52,926] Epoch: 157
[2022-06-16 12:06:02,515] Train: Loss: 2.265 | Acc: 49.883 (639090/1281167) | Lr: 0.4550744844701241
[2022-06-16 12:06:51,156] Test: Loss: 2.254 | Acc: 49.148 (24574/50000)
[2022-06-16 12:06:51,156] Epoch: 158
[2022-06-16 12:25:11,250] Train: Loss: 2.258 | Acc: 49.929 (639674/1281167) | Lr: 0.4533903693576845
[2022-06-16 12:26:05,876] Test: Loss: 2.135 | Acc: 50.964 (25482/50000)
[2022-06-16 12:26:05,877] Epoch: 159
[2022-06-16 12:44:32,495] Train: Loss: 2.262 | Acc: 49.904 (639351/1281167) | Lr: 0.4516996837265278
[2022-06-16 12:45:26,158] Test: Loss: 2.163 | Acc: 50.312 (25156/50000)
[2022-06-16 12:45:26,158] Epoch: 160
[2022-06-16 13:03:46,346] Train: Loss: 2.256 | Acc: 50.029 (640958/1281167) | Lr: 0.4500024999999993
[2022-06-16 13:04:35,917] Test: Loss: 2.257 | Acc: 49.570 (24785/50000)
[2022-06-16 13:04:35,918] Epoch: 161
[2022-06-16 13:22:59,294] Train: Loss: 2.253 | Acc: 50.071 (641495/1281167) | Lr: 0.44829889087980124
[2022-06-16 13:23:50,036] Test: Loss: 1.977 | Acc: 53.688 (26844/50000)
[2022-06-16 13:23:50,036] Epoch: 162
[2022-06-16 13:42:06,611] Train: Loss: 2.254 | Acc: 50.049 (641215/1281167) | Lr: 0.4465889293428783
[2022-06-16 13:42:55,496] Test: Loss: 2.163 | Acc: 50.334 (25167/50000)
[2022-06-16 13:42:55,497] Epoch: 163
[2022-06-16 14:01:17,984] Train: Loss: 2.250 | Acc: 50.126 (642198/1281167) | Lr: 0.44487268863829144
[2022-06-16 14:02:07,002] Test: Loss: 2.132 | Acc: 51.192 (25596/50000)
[2022-06-16 14:02:07,003] Epoch: 164
[2022-06-16 14:20:40,303] Train: Loss: 2.248 | Acc: 50.129 (642236/1281167) | Lr: 0.44315024228408056
[2022-06-16 14:21:29,749] Test: Loss: 2.092 | Acc: 51.964 (25982/50000)
[2022-06-16 14:21:29,750] Epoch: 165
[2022-06-16 14:39:56,940] Train: Loss: 2.249 | Acc: 50.158 (642602/1281167) | Lr: 0.44142166406411454
[2022-06-16 14:40:49,826] Test: Loss: 1.937 | Acc: 54.696 (27348/50000)
[2022-06-16 14:40:49,826] Epoch: 166
[2022-06-16 14:59:09,973] Train: Loss: 2.245 | Acc: 50.209 (643258/1281167) | Lr: 0.4396870280249311
[2022-06-16 14:59:58,662] Test: Loss: 2.239 | Acc: 48.972 (24486/50000)
[2022-06-16 14:59:58,663] Epoch: 167
[2022-06-16 15:18:17,580] Train: Loss: 2.244 | Acc: 50.249 (643778/1281167) | Lr: 0.437946408472565
[2022-06-16 15:19:07,230] Test: Loss: 2.168 | Acc: 50.316 (25158/50000)
[2022-06-16 15:19:07,230] Epoch: 168
[2022-06-16 15:37:46,889] Train: Loss: 2.244 | Acc: 50.213 (643310/1281167) | Lr: 0.43619987996936466
[2022-06-16 15:38:34,859] Test: Loss: 2.040 | Acc: 52.726 (26363/50000)
[2022-06-16 15:38:34,859] Epoch: 169
[2022-06-16 15:57:19,459] Train: Loss: 2.242 | Acc: 50.291 (644317/1281167) | Lr: 0.4344475173307981
[2022-06-16 15:58:07,343] Test: Loss: 2.145 | Acc: 51.002 (25501/50000)
[2022-06-16 15:58:07,343] Epoch: 170
[2022-06-16 16:17:01,170] Train: Loss: 2.240 | Acc: 50.290 (644296/1281167) | Lr: 0.4326893956222486
[2022-06-16 16:17:48,964] Test: Loss: 1.958 | Acc: 54.614 (27307/50000)
[2022-06-16 16:17:48,964] Epoch: 171
[2022-06-16 16:36:26,381] Train: Loss: 2.238 | Acc: 50.392 (645600/1281167) | Lr: 0.4309255901557986
[2022-06-16 16:37:25,516] Test: Loss: 2.185 | Acc: 50.214 (25107/50000)
[2022-06-16 16:37:25,516] Epoch: 172
[2022-06-16 16:55:58,868] Train: Loss: 2.235 | Acc: 50.429 (646081/1281167) | Lr: 0.4291561764870039
[2022-06-16 16:56:48,741] Test: Loss: 2.162 | Acc: 49.810 (24905/50000)
[2022-06-16 16:56:48,742] Epoch: 173
[2022-06-16 17:15:41,794] Train: Loss: 2.234 | Acc: 50.409 (645825/1281167) | Lr: 0.42738123041165693
[2022-06-16 17:16:34,728] Test: Loss: 1.887 | Acc: 55.612 (27806/50000)
[2022-06-16 17:16:34,728] Saving..
[2022-06-16 17:16:34,813] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-16 17:16:34,813] Epoch: 174
[2022-06-16 17:35:16,009] Train: Loss: 2.232 | Acc: 50.427 (646051/1281167) | Lr: 0.4256008279625401
[2022-06-16 17:36:04,507] Test: Loss: 2.239 | Acc: 49.634 (24817/50000)
[2022-06-16 17:36:04,507] Epoch: 175
[2022-06-16 17:54:34,859] Train: Loss: 2.230 | Acc: 50.551 (647649/1281167) | Lr: 0.4238150454061688
[2022-06-16 17:55:23,781] Test: Loss: 1.972 | Acc: 54.060 (27030/50000)
[2022-06-16 17:55:23,781] Epoch: 176
[2022-06-16 18:13:48,591] Train: Loss: 2.223 | Acc: 50.663 (649077/1281167) | Lr: 0.4220239592395241
[2022-06-16 18:14:48,535] Test: Loss: 2.019 | Acc: 53.088 (26544/50000)
[2022-06-16 18:14:48,536] Epoch: 177
[2022-06-16 18:33:28,380] Train: Loss: 2.225 | Acc: 50.641 (648790/1281167) | Lr: 0.4202276461867761
[2022-06-16 18:34:16,630] Test: Loss: 1.897 | Acc: 55.338 (27669/50000)
[2022-06-16 18:34:16,630] Epoch: 178
[2022-06-16 18:52:46,600] Train: Loss: 2.227 | Acc: 50.596 (648214/1281167) | Lr: 0.4184261831959976
[2022-06-16 18:53:33,616] Test: Loss: 2.188 | Acc: 50.526 (25263/50000)
[2022-06-16 18:53:33,616] Epoch: 179
[2022-06-16 19:12:06,752] Train: Loss: 2.223 | Acc: 50.661 (649053/1281167) | Lr: 0.4166196474358673
[2022-06-16 19:12:52,977] Test: Loss: 2.225 | Acc: 49.318 (24659/50000)
[2022-06-16 19:12:52,977] Epoch: 180
[2022-06-16 19:31:23,954] Train: Loss: 2.220 | Acc: 50.676 (649250/1281167) | Lr: 0.4148081162923645
[2022-06-16 19:32:11,566] Test: Loss: 2.016 | Acc: 52.872 (26436/50000)
[2022-06-16 19:32:11,566] Epoch: 181
[2022-06-16 19:50:37,787] Train: Loss: 2.217 | Acc: 50.754 (650245/1281167) | Lr: 0.4129916673654542
[2022-06-16 19:51:30,905] Test: Loss: 2.275 | Acc: 48.738 (24369/50000)
[2022-06-16 19:51:30,905] Epoch: 182
[2022-06-16 20:09:54,282] Train: Loss: 2.215 | Acc: 50.788 (650677/1281167) | Lr: 0.4111703784657627
[2022-06-16 20:10:47,378] Test: Loss: 2.227 | Acc: 49.258 (24629/50000)
[2022-06-16 20:10:47,379] Epoch: 183
[2022-06-16 20:29:13,823] Train: Loss: 2.214 | Acc: 50.840 (651347/1281167) | Lr: 0.409344327611245
[2022-06-16 20:30:05,959] Test: Loss: 1.926 | Acc: 54.790 (27395/50000)
[2022-06-16 20:30:05,960] Epoch: 184
[2022-06-16 20:48:44,056] Train: Loss: 2.210 | Acc: 50.941 (652641/1281167) | Lr: 0.4075135930238419
[2022-06-16 20:49:32,337] Test: Loss: 1.861 | Acc: 56.172 (28086/50000)
[2022-06-16 20:49:32,337] Saving..
[2022-06-16 20:49:32,424] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-16 20:49:32,424] Epoch: 185
[2022-06-16 21:08:02,733] Train: Loss: 2.211 | Acc: 50.809 (650947/1281167) | Lr: 0.40567825312612993
[2022-06-16 21:08:51,954] Test: Loss: 1.939 | Acc: 54.654 (27327/50000)
[2022-06-16 21:08:51,954] Epoch: 186
[2022-06-16 21:27:19,159] Train: Loss: 2.209 | Acc: 50.913 (652283/1281167) | Lr: 0.403838386537962
[2022-06-16 21:28:17,072] Test: Loss: 2.043 | Acc: 52.896 (26448/50000)
[2022-06-16 21:28:17,072] Epoch: 187
[2022-06-16 21:46:52,749] Train: Loss: 2.206 | Acc: 50.981 (653157/1281167) | Lr: 0.4019940720730991
[2022-06-16 21:47:43,206] Test: Loss: 1.986 | Acc: 53.784 (26892/50000)
[2022-06-16 21:47:43,206] Epoch: 188
[2022-06-16 22:06:06,042] Train: Loss: 2.201 | Acc: 51.020 (653646/1281167) | Lr: 0.4001453887358346
[2022-06-16 22:06:58,738] Test: Loss: 1.946 | Acc: 54.744 (27372/50000)
[2022-06-16 22:06:58,738] Epoch: 189
[2022-06-16 22:25:20,738] Train: Loss: 2.204 | Acc: 51.008 (653496/1281167) | Lr: 0.39829241571760976
[2022-06-16 22:26:11,196] Test: Loss: 2.002 | Acc: 53.370 (26685/50000)
[2022-06-16 22:26:11,197] Epoch: 190
[2022-06-16 22:44:44,017] Train: Loss: 2.203 | Acc: 51.027 (653737/1281167) | Lr: 0.3964352323936215
[2022-06-16 22:45:36,214] Test: Loss: 2.538 | Acc: 45.166 (22583/50000)
[2022-06-16 22:45:36,215] Epoch: 191
[2022-06-16 23:04:10,118] Train: Loss: 2.198 | Acc: 51.153 (655355/1281167) | Lr: 0.39457391831942223
[2022-06-16 23:04:58,184] Test: Loss: 2.003 | Acc: 53.118 (26559/50000)
[2022-06-16 23:04:58,184] Epoch: 192
[2022-06-16 23:23:35,628] Train: Loss: 2.196 | Acc: 51.162 (655468/1281167) | Lr: 0.3927085532275119
[2022-06-16 23:24:23,482] Test: Loss: 2.003 | Acc: 53.438 (26719/50000)
[2022-06-16 23:24:23,482] Epoch: 193
[2022-06-16 23:43:15,103] Train: Loss: 2.196 | Acc: 51.143 (655230/1281167) | Lr: 0.39083921702392277
[2022-06-16 23:44:02,900] Test: Loss: 2.026 | Acc: 53.368 (26684/50000)
[2022-06-16 23:44:02,900] Epoch: 194
[2022-06-17 00:02:51,718] Train: Loss: 2.193 | Acc: 51.188 (655798/1281167) | Lr: 0.388965989784796
[2022-06-17 00:03:48,014] Test: Loss: 1.931 | Acc: 54.904 (27452/50000)
[2022-06-17 00:03:48,014] Epoch: 195
[2022-06-17 00:22:11,734] Train: Loss: 2.190 | Acc: 51.276 (656935/1281167) | Lr: 0.38708895175295205
[2022-06-17 00:23:00,132] Test: Loss: 1.909 | Acc: 55.058 (27529/50000)
[2022-06-17 00:23:00,132] Epoch: 196
[2022-06-17 00:41:28,496] Train: Loss: 2.188 | Acc: 51.332 (657644/1281167) | Lr: 0.3852081833344529
[2022-06-17 00:42:17,388] Test: Loss: 1.929 | Acc: 55.196 (27598/50000)
[2022-06-17 00:42:17,389] Epoch: 197
[2022-06-17 01:00:45,920] Train: Loss: 2.188 | Acc: 51.247 (656560/1281167) | Lr: 0.38332376509515786
[2022-06-17 01:01:37,239] Test: Loss: 2.458 | Acc: 45.792 (22896/50000)
[2022-06-17 01:01:37,239] Epoch: 198
[2022-06-17 01:19:55,531] Train: Loss: 2.182 | Acc: 51.437 (658998/1281167) | Lr: 0.3814357777572725
[2022-06-17 01:20:57,540] Test: Loss: 2.016 | Acc: 52.902 (26451/50000)
[2022-06-17 01:20:57,541] Epoch: 199
[2022-06-17 01:39:18,181] Train: Loss: 2.179 | Acc: 51.487 (659636/1281167) | Lr: 0.37954430219589075
[2022-06-17 01:40:09,275] Test: Loss: 2.110 | Acc: 51.732 (25866/50000)
[2022-06-17 01:40:09,275] Epoch: 200
[2022-06-17 01:58:25,362] Train: Loss: 2.182 | Acc: 51.400 (658519/1281167) | Lr: 0.37764941943553026
[2022-06-17 01:59:16,034] Test: Loss: 1.885 | Acc: 55.812 (27906/50000)
[2022-06-17 01:59:16,035] Epoch: 201
[2022-06-17 02:17:46,105] Train: Loss: 2.178 | Acc: 51.447 (659119/1281167) | Lr: 0.37575121064666184
[2022-06-17 02:18:35,454] Test: Loss: 2.200 | Acc: 50.360 (25180/50000)
[2022-06-17 02:18:35,454] Epoch: 202
[2022-06-17 02:37:08,949] Train: Loss: 2.172 | Acc: 51.598 (661051/1281167) | Lr: 0.37384975714223234
[2022-06-17 02:37:58,227] Test: Loss: 2.415 | Acc: 46.828 (23414/50000)
[2022-06-17 02:37:58,227] Epoch: 203
[2022-06-17 02:56:33,750] Train: Loss: 2.173 | Acc: 51.565 (660630/1281167) | Lr: 0.37194514037418125
[2022-06-17 02:57:22,106] Test: Loss: 1.916 | Acc: 55.292 (27646/50000)
[2022-06-17 02:57:22,107] Epoch: 204
[2022-06-17 03:15:37,758] Train: Loss: 2.170 | Acc: 51.679 (662089/1281167) | Lr: 0.3700374419299519
[2022-06-17 03:16:27,889] Test: Loss: 1.882 | Acc: 55.674 (27837/50000)
[2022-06-17 03:16:27,890] Epoch: 205
[2022-06-17 03:35:08,816] Train: Loss: 2.171 | Acc: 51.598 (661054/1281167) | Lr: 0.3681267435289963
[2022-06-17 03:35:59,024] Test: Loss: 1.930 | Acc: 55.022 (27511/50000)
[2022-06-17 03:35:59,024] Epoch: 206
[2022-06-17 03:54:29,302] Train: Loss: 2.169 | Acc: 51.687 (662196/1281167) | Lr: 0.3662131270192749
[2022-06-17 03:55:24,712] Test: Loss: 2.183 | Acc: 49.990 (24995/50000)
[2022-06-17 03:55:24,712] Epoch: 207
[2022-06-17 04:13:48,843] Train: Loss: 2.168 | Acc: 51.672 (662010/1281167) | Lr: 0.3642966743737495
[2022-06-17 04:14:42,800] Test: Loss: 1.723 | Acc: 58.512 (29256/50000)
[2022-06-17 04:14:42,801] Saving..
[2022-06-17 04:14:42,889] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 04:14:42,889] Epoch: 208
[2022-06-17 04:33:15,775] Train: Loss: 2.161 | Acc: 51.746 (662951/1281167) | Lr: 0.36237746768687323
[2022-06-17 04:34:03,965] Test: Loss: 1.942 | Acc: 54.672 (27336/50000)
[2022-06-17 04:34:03,966] Epoch: 209
[2022-06-17 04:52:27,548] Train: Loss: 2.163 | Acc: 51.826 (663975/1281167) | Lr: 0.360455589171073
[2022-06-17 04:53:15,177] Test: Loss: 1.832 | Acc: 56.542 (28271/50000)
[2022-06-17 04:53:15,178] Epoch: 210
[2022-06-17 05:11:59,448] Train: Loss: 2.162 | Acc: 51.829 (664021/1281167) | Lr: 0.358531121153228
[2022-06-17 05:12:46,158] Test: Loss: 1.956 | Acc: 54.416 (27208/50000)
[2022-06-17 05:12:46,159] Epoch: 211
[2022-06-17 05:31:13,291] Train: Loss: 2.158 | Acc: 51.907 (665013/1281167) | Lr: 0.3566041460711427
[2022-06-17 05:32:02,012] Test: Loss: 1.888 | Acc: 55.590 (27795/50000)
[2022-06-17 05:32:02,013] Epoch: 212
[2022-06-17 05:50:46,481] Train: Loss: 2.151 | Acc: 51.992 (666106/1281167) | Lr: 0.35467474647001634
[2022-06-17 05:51:35,320] Test: Loss: 2.011 | Acc: 53.204 (26602/50000)
[2022-06-17 05:51:35,320] Epoch: 213
[2022-06-17 06:10:22,990] Train: Loss: 2.154 | Acc: 51.964 (665740/1281167) | Lr: 0.3527430049989062
[2022-06-17 06:11:11,952] Test: Loss: 2.228 | Acc: 49.580 (24790/50000)
[2022-06-17 06:11:11,952] Epoch: 214
[2022-06-17 06:29:40,835] Train: Loss: 2.153 | Acc: 52.023 (666498/1281167) | Lr: 0.3508090044071877
[2022-06-17 06:30:29,735] Test: Loss: 1.764 | Acc: 57.968 (28984/50000)
[2022-06-17 06:30:29,736] Epoch: 215
[2022-06-17 06:49:22,083] Train: Loss: 2.148 | Acc: 52.104 (667539/1281167) | Lr: 0.34887282754100923
[2022-06-17 06:50:10,289] Test: Loss: 1.967 | Acc: 54.106 (27053/50000)
[2022-06-17 06:50:10,290] Epoch: 216
[2022-06-17 07:08:44,776] Train: Loss: 2.147 | Acc: 52.089 (667349/1281167) | Lr: 0.3469345573397436
[2022-06-17 07:09:36,763] Test: Loss: 1.836 | Acc: 56.470 (28235/50000)
[2022-06-17 07:09:36,764] Epoch: 217
[2022-06-17 07:28:23,689] Train: Loss: 2.142 | Acc: 52.142 (668021/1281167) | Lr: 0.3449942768324353
[2022-06-17 07:29:09,819] Test: Loss: 1.800 | Acc: 57.184 (28592/50000)
[2022-06-17 07:29:09,819] Epoch: 218
[2022-06-17 07:48:09,495] Train: Loss: 2.145 | Acc: 52.094 (667405/1281167) | Lr: 0.34305206913424346
[2022-06-17 07:48:57,035] Test: Loss: 1.932 | Acc: 54.540 (27270/50000)
[2022-06-17 07:48:57,035] Epoch: 219
[2022-06-17 08:07:45,139] Train: Loss: 2.138 | Acc: 52.193 (668680/1281167) | Lr: 0.3411080174428815
[2022-06-17 08:08:35,417] Test: Loss: 1.813 | Acc: 57.600 (28800/50000)
[2022-06-17 08:08:35,417] Epoch: 220
[2022-06-17 08:27:04,540] Train: Loss: 2.136 | Acc: 52.330 (670438/1281167) | Lr: 0.3391622050350539
[2022-06-17 08:27:54,213] Test: Loss: 1.936 | Acc: 54.588 (27294/50000)
[2022-06-17 08:27:54,213] Epoch: 221
[2022-06-17 08:46:43,474] Train: Loss: 2.130 | Acc: 52.393 (671244/1281167) | Lr: 0.3372147152628879
[2022-06-17 08:47:33,252] Test: Loss: 1.933 | Acc: 55.060 (27530/50000)
[2022-06-17 08:47:33,253] Epoch: 222
[2022-06-17 09:06:01,959] Train: Loss: 2.133 | Acc: 52.365 (670889/1281167) | Lr: 0.33526563155036354
[2022-06-17 09:06:49,444] Test: Loss: 1.853 | Acc: 56.504 (28252/50000)
[2022-06-17 09:06:49,445] Epoch: 223
[2022-06-17 09:25:23,035] Train: Loss: 2.127 | Acc: 52.486 (672438/1281167) | Lr: 0.33331503738974005
[2022-06-17 09:26:11,984] Test: Loss: 1.939 | Acc: 54.914 (27457/50000)
[2022-06-17 09:26:11,984] Epoch: 224
[2022-06-17 09:44:39,089] Train: Loss: 2.125 | Acc: 52.470 (672228/1281167) | Lr: 0.33136301633797927
[2022-06-17 09:45:27,054] Test: Loss: 1.877 | Acc: 55.772 (27886/50000)
[2022-06-17 09:45:27,054] Epoch: 225
[2022-06-17 10:03:51,426] Train: Loss: 2.124 | Acc: 52.540 (673122/1281167) | Lr: 0.3294096520131662
[2022-06-17 10:04:39,949] Test: Loss: 1.719 | Acc: 58.950 (29475/50000)
[2022-06-17 10:04:39,950] Saving..
[2022-06-17 10:04:40,070] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 10:04:40,071] Epoch: 226
[2022-06-17 10:23:17,404] Train: Loss: 2.120 | Acc: 52.569 (673501/1281167) | Lr: 0.327455028090927
[2022-06-17 10:24:10,601] Test: Loss: 1.921 | Acc: 54.880 (27440/50000)
[2022-06-17 10:24:10,601] Epoch: 227
[2022-06-17 10:42:38,278] Train: Loss: 2.123 | Acc: 52.534 (673050/1281167) | Lr: 0.32549922830084527
[2022-06-17 10:43:30,587] Test: Loss: 1.795 | Acc: 57.354 (28677/50000)
[2022-06-17 10:43:30,587] Epoch: 228
[2022-06-17 11:02:04,076] Train: Loss: 2.116 | Acc: 52.664 (674715/1281167) | Lr: 0.3235423364228745
[2022-06-17 11:02:56,737] Test: Loss: 1.863 | Acc: 56.640 (28320/50000)
[2022-06-17 11:02:56,737] Epoch: 229
[2022-06-17 11:21:23,932] Train: Loss: 2.117 | Acc: 52.607 (673978/1281167) | Lr: 0.3215844362837498
[2022-06-17 11:22:15,685] Test: Loss: 1.760 | Acc: 58.168 (29084/50000)
[2022-06-17 11:22:15,685] Epoch: 230
[2022-06-17 11:41:03,415] Train: Loss: 2.110 | Acc: 52.784 (676253/1281167) | Lr: 0.31962561175339643
[2022-06-17 11:41:53,651] Test: Loss: 1.750 | Acc: 58.368 (29184/50000)
[2022-06-17 11:41:53,651] Epoch: 231
[2022-06-17 12:00:21,786] Train: Loss: 2.110 | Acc: 52.760 (675942/1281167) | Lr: 0.3176659467413381
[2022-06-17 12:01:14,191] Test: Loss: 1.741 | Acc: 58.650 (29325/50000)
[2022-06-17 12:01:14,192] Epoch: 232
[2022-06-17 12:19:53,875] Train: Loss: 2.106 | Acc: 52.892 (677641/1281167) | Lr: 0.3157055251931016
[2022-06-17 12:20:44,994] Test: Loss: 1.741 | Acc: 58.928 (29464/50000)
[2022-06-17 12:20:44,995] Epoch: 233
[2022-06-17 12:39:09,432] Train: Loss: 2.105 | Acc: 52.902 (677759/1281167) | Lr: 0.3137444310866212
[2022-06-17 12:39:58,962] Test: Loss: 1.748 | Acc: 58.322 (29161/50000)
[2022-06-17 12:39:58,962] Epoch: 234
[2022-06-17 12:58:34,799] Train: Loss: 2.102 | Acc: 52.885 (677544/1281167) | Lr: 0.31178274842864145
[2022-06-17 12:59:24,966] Test: Loss: 1.750 | Acc: 58.204 (29102/50000)
[2022-06-17 12:59:24,966] Epoch: 235
[2022-06-17 13:18:15,917] Train: Loss: 2.099 | Acc: 53.045 (679590/1281167) | Lr: 0.30982056125111845
[2022-06-17 13:19:09,473] Test: Loss: 1.952 | Acc: 54.688 (27344/50000)
[2022-06-17 13:19:09,473] Epoch: 236
[2022-06-17 13:37:36,843] Train: Loss: 2.096 | Acc: 53.108 (680405/1281167) | Lr: 0.3078579536076201
[2022-06-17 13:38:34,575] Test: Loss: 1.717 | Acc: 58.852 (29426/50000)
[2022-06-17 13:38:34,576] Epoch: 237
[2022-06-17 13:57:22,541] Train: Loss: 2.094 | Acc: 53.139 (680802/1281167) | Lr: 0.30589500956972593
[2022-06-17 13:58:17,720] Test: Loss: 1.848 | Acc: 56.472 (28236/50000)
[2022-06-17 13:58:17,721] Epoch: 238
[2022-06-17 14:16:42,449] Train: Loss: 2.095 | Acc: 53.102 (680323/1281167) | Lr: 0.3039318132234252
[2022-06-17 14:17:34,853] Test: Loss: 1.735 | Acc: 58.522 (29261/50000)
[2022-06-17 14:17:34,853] Epoch: 239
[2022-06-17 14:36:12,585] Train: Loss: 2.091 | Acc: 53.202 (681609/1281167) | Lr: 0.3019684486655154
[2022-06-17 14:37:05,504] Test: Loss: 2.173 | Acc: 50.430 (25215/50000)
[2022-06-17 14:37:05,505] Epoch: 240
[2022-06-17 14:55:32,876] Train: Loss: 2.058 | Acc: 53.758 (688730/1281167) | Lr: 0.30000499999999974
[2022-06-17 14:56:24,145] Test: Loss: 1.729 | Acc: 58.564 (29282/50000)
[2022-06-17 14:56:24,146] Epoch: 241
[2022-06-17 15:15:13,008] Train: Loss: 2.051 | Acc: 53.899 (690538/1281167) | Lr: 0.29804155133448396
[2022-06-17 15:15:57,791] Test: Loss: 1.939 | Acc: 54.880 (27440/50000)
[2022-06-17 15:15:57,793] Epoch: 242
[2022-06-17 15:34:46,382] Train: Loss: 2.046 | Acc: 54.038 (692322/1281167) | Lr: 0.29607818677657416
[2022-06-17 15:35:31,057] Test: Loss: 1.826 | Acc: 57.166 (28583/50000)
[2022-06-17 15:35:31,057] Epoch: 243
[2022-06-17 15:54:00,171] Train: Loss: 2.042 | Acc: 54.126 (693439/1281167) | Lr: 0.29411499043027345
[2022-06-17 15:54:47,966] Test: Loss: 1.815 | Acc: 57.272 (28636/50000)
[2022-06-17 15:54:47,967] Epoch: 244
[2022-06-17 16:13:11,971] Train: Loss: 2.038 | Acc: 54.182 (694159/1281167) | Lr: 0.2921520463923793
[2022-06-17 16:14:01,776] Test: Loss: 1.748 | Acc: 58.338 (29169/50000)
[2022-06-17 16:14:01,777] Epoch: 245
[2022-06-17 16:32:52,897] Train: Loss: 2.030 | Acc: 54.364 (696492/1281167) | Lr: 0.290189438748881
[2022-06-17 16:33:42,907] Test: Loss: 1.841 | Acc: 56.872 (28436/50000)
[2022-06-17 16:33:42,908] Epoch: 246
[2022-06-17 16:52:16,448] Train: Loss: 2.031 | Acc: 54.313 (695838/1281167) | Lr: 0.2882272515713579
[2022-06-17 16:53:04,642] Test: Loss: 1.693 | Acc: 59.202 (29601/50000)
[2022-06-17 16:53:04,643] Saving..
[2022-06-17 16:53:04,726] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 16:53:04,727] Epoch: 247
[2022-06-17 17:11:40,686] Train: Loss: 2.026 | Acc: 54.391 (696838/1281167) | Lr: 0.2862655689133781
[2022-06-17 17:12:33,855] Test: Loss: 1.622 | Acc: 60.990 (30495/50000)
[2022-06-17 17:12:33,856] Saving..
[2022-06-17 17:12:33,937] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 17:12:33,938] Epoch: 248
[2022-06-17 17:31:09,223] Train: Loss: 2.022 | Acc: 54.457 (697686/1281167) | Lr: 0.2843044748068978
[2022-06-17 17:31:58,243] Test: Loss: 1.735 | Acc: 58.792 (29396/50000)
[2022-06-17 17:31:58,245] Epoch: 249
[2022-06-17 17:50:25,595] Train: Loss: 2.019 | Acc: 54.554 (698933/1281167) | Lr: 0.2823440532586613
[2022-06-17 17:51:15,132] Test: Loss: 1.897 | Acc: 55.496 (27748/50000)
[2022-06-17 17:51:15,133] Epoch: 250
[2022-06-17 18:09:52,792] Train: Loss: 2.017 | Acc: 54.595 (699453/1281167) | Lr: 0.280384388246603
[2022-06-17 18:10:42,593] Test: Loss: 1.686 | Acc: 59.560 (29780/50000)
[2022-06-17 18:10:42,595] Epoch: 251
[2022-06-17 18:29:09,749] Train: Loss: 2.009 | Acc: 54.738 (701282/1281167) | Lr: 0.27842556371624966
[2022-06-17 18:29:58,890] Test: Loss: 1.717 | Acc: 58.986 (29493/50000)
[2022-06-17 18:29:58,890] Epoch: 252
[2022-06-17 18:48:31,157] Train: Loss: 2.010 | Acc: 54.727 (701148/1281167) | Lr: 0.27646766357712493
[2022-06-17 18:49:21,330] Test: Loss: 1.622 | Acc: 61.110 (30555/50000)
[2022-06-17 18:49:21,331] Saving..
[2022-06-17 18:49:21,418] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 18:49:21,419] Epoch: 253
[2022-06-17 19:07:55,487] Train: Loss: 2.001 | Acc: 54.895 (703297/1281167) | Lr: 0.2745107716991541
[2022-06-17 19:08:44,841] Test: Loss: 1.720 | Acc: 59.076 (29538/50000)
[2022-06-17 19:08:44,842] Epoch: 254
[2022-06-17 19:27:32,454] Train: Loss: 2.005 | Acc: 54.844 (702638/1281167) | Lr: 0.27255497190907235
[2022-06-17 19:28:27,051] Test: Loss: 1.848 | Acc: 56.620 (28310/50000)
[2022-06-17 19:28:27,052] Epoch: 255
[2022-06-17 19:47:16,353] Train: Loss: 2.002 | Acc: 54.839 (702579/1281167) | Lr: 0.2706003479868332
[2022-06-17 19:48:10,007] Test: Loss: 1.644 | Acc: 60.582 (30291/50000)
[2022-06-17 19:48:10,008] Epoch: 256
[2022-06-17 20:06:53,407] Train: Loss: 1.998 | Acc: 54.924 (703667/1281167) | Lr: 0.2686469836620201
[2022-06-17 20:07:49,687] Test: Loss: 1.586 | Acc: 61.430 (30715/50000)
[2022-06-17 20:07:49,687] Saving..
[2022-06-17 20:07:49,768] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 20:07:49,769] Epoch: 257
[2022-06-17 20:26:24,385] Train: Loss: 1.991 | Acc: 55.035 (705096/1281167) | Lr: 0.26669496261025927
[2022-06-17 20:27:19,339] Test: Loss: 1.639 | Acc: 60.638 (30319/50000)
[2022-06-17 20:27:19,340] Epoch: 258
[2022-06-17 20:46:03,814] Train: Loss: 1.992 | Acc: 55.039 (705144/1281167) | Lr: 0.2647443684496358
[2022-06-17 20:46:54,764] Test: Loss: 1.750 | Acc: 58.388 (29194/50000)
[2022-06-17 20:46:54,766] Epoch: 259
[2022-06-17 21:05:30,385] Train: Loss: 1.992 | Acc: 55.069 (705524/1281167) | Lr: 0.2627952847371114
[2022-06-17 21:06:19,370] Test: Loss: 1.585 | Acc: 61.592 (30796/50000)
[2022-06-17 21:06:19,371] Saving..
[2022-06-17 21:06:19,449] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 21:06:19,450] Epoch: 260
[2022-06-17 21:24:31,455] Train: Loss: 1.984 | Acc: 55.172 (706842/1281167) | Lr: 0.2608477949649454
[2022-06-17 21:25:20,204] Test: Loss: 1.594 | Acc: 61.776 (30888/50000)
[2022-06-17 21:25:20,204] Saving..
[2022-06-17 21:25:20,280] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-17 21:25:20,280] Epoch: 261
[2022-06-17 21:43:40,847] Train: Loss: 1.977 | Acc: 55.363 (709293/1281167) | Lr: 0.25890198255711777
[2022-06-17 21:44:30,834] Test: Loss: 1.665 | Acc: 60.192 (30096/50000)
[2022-06-17 21:44:30,835] Epoch: 262
[2022-06-17 22:02:35,198] Train: Loss: 1.980 | Acc: 55.237 (707672/1281167) | Lr: 0.25695793086575586
[2022-06-17 22:03:24,829] Test: Loss: 1.655 | Acc: 60.212 (30106/50000)
[2022-06-17 22:03:24,830] Epoch: 263
[2022-06-17 22:21:35,785] Train: Loss: 1.976 | Acc: 55.416 (709976/1281167) | Lr: 0.25501572316756393
[2022-06-17 22:22:24,404] Test: Loss: 1.680 | Acc: 59.602 (29801/50000)
[2022-06-17 22:22:24,405] Epoch: 264
[2022-06-17 22:40:33,968] Train: Loss: 1.973 | Acc: 55.408 (709873/1281167) | Lr: 0.25307544266025567
[2022-06-17 22:41:23,391] Test: Loss: 1.746 | Acc: 58.644 (29322/50000)
[2022-06-17 22:41:23,392] Epoch: 265
[2022-06-17 22:59:54,567] Train: Loss: 1.971 | Acc: 55.495 (710983/1281167) | Lr: 0.2511371724589901
[2022-06-17 23:00:44,971] Test: Loss: 1.725 | Acc: 58.874 (29437/50000)
[2022-06-17 23:00:44,973] Epoch: 266
[2022-06-17 23:18:57,252] Train: Loss: 1.968 | Acc: 55.547 (711649/1281167) | Lr: 0.24920099559281159
[2022-06-17 23:19:46,011] Test: Loss: 1.633 | Acc: 60.620 (30310/50000)
[2022-06-17 23:19:46,013] Epoch: 267
[2022-06-17 23:38:10,290] Train: Loss: 1.965 | Acc: 55.607 (712423/1281167) | Lr: 0.2472669950010931
[2022-06-17 23:38:59,214] Test: Loss: 1.869 | Acc: 56.158 (28079/50000)
[2022-06-17 23:38:59,217] Epoch: 268
[2022-06-17 23:57:11,726] Train: Loss: 1.960 | Acc: 55.649 (712961/1281167) | Lr: 0.245335253529983
[2022-06-17 23:58:09,593] Test: Loss: 1.678 | Acc: 59.924 (29962/50000)
[2022-06-17 23:58:09,594] Epoch: 269
[2022-06-18 00:16:31,357] Train: Loss: 1.959 | Acc: 55.687 (713439/1281167) | Lr: 0.24340585392885664
[2022-06-18 00:17:21,353] Test: Loss: 1.673 | Acc: 60.230 (30115/50000)
[2022-06-18 00:17:21,354] Epoch: 270
[2022-06-18 00:35:30,110] Train: Loss: 1.957 | Acc: 55.762 (714401/1281167) | Lr: 0.24147887884677136
[2022-06-18 00:36:18,792] Test: Loss: 1.617 | Acc: 60.970 (30485/50000)
[2022-06-18 00:36:18,793] Epoch: 271
[2022-06-18 00:54:35,052] Train: Loss: 1.955 | Acc: 55.792 (714785/1281167) | Lr: 0.23955441082892628
[2022-06-18 00:55:24,642] Test: Loss: 1.594 | Acc: 61.828 (30914/50000)
[2022-06-18 00:55:24,643] Saving..
[2022-06-18 00:55:24,736] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 00:55:24,737] Epoch: 272
[2022-06-18 01:13:35,962] Train: Loss: 1.950 | Acc: 55.834 (715333/1281167) | Lr: 0.237632532313126
[2022-06-18 01:15:37,072] Test: Loss: 1.599 | Acc: 61.702 (30851/50000)
[2022-06-18 01:15:37,073] Epoch: 273
[2022-06-18 01:33:23,656] Train: Loss: 1.945 | Acc: 55.957 (716903/1281167) | Lr: 0.2357133256262498
[2022-06-18 01:34:13,592] Test: Loss: 1.631 | Acc: 60.936 (30468/50000)
[2022-06-18 01:34:13,593] Epoch: 274
[2022-06-18 01:52:19,497] Train: Loss: 1.943 | Acc: 55.996 (717397/1281167) | Lr: 0.23379687298072446
[2022-06-18 01:53:11,181] Test: Loss: 1.591 | Acc: 61.382 (30691/50000)
[2022-06-18 01:53:11,182] Epoch: 275
[2022-06-18 02:11:21,327] Train: Loss: 1.941 | Acc: 56.029 (717827/1281167) | Lr: 0.23188325647100297
[2022-06-18 02:12:11,083] Test: Loss: 1.919 | Acc: 55.328 (27664/50000)
[2022-06-18 02:12:11,084] Epoch: 276
[2022-06-18 02:30:26,649] Train: Loss: 1.935 | Acc: 56.147 (719331/1281167) | Lr: 0.2299725580700474
[2022-06-18 02:31:16,951] Test: Loss: 1.587 | Acc: 61.772 (30886/50000)
[2022-06-18 02:31:16,953] Epoch: 277
[2022-06-18 02:49:26,055] Train: Loss: 1.933 | Acc: 56.227 (720363/1281167) | Lr: 0.22806485962581804
[2022-06-18 02:50:27,605] Test: Loss: 1.657 | Acc: 60.532 (30266/50000)
[2022-06-18 02:50:27,607] Epoch: 278
[2022-06-18 03:08:48,837] Train: Loss: 1.931 | Acc: 56.190 (719884/1281167) | Lr: 0.22616024285776695
[2022-06-18 03:09:39,328] Test: Loss: 1.526 | Acc: 63.184 (31592/50000)
[2022-06-18 03:09:39,328] Saving..
[2022-06-18 03:09:39,419] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 03:09:39,419] Epoch: 279
[2022-06-18 03:28:05,447] Train: Loss: 1.928 | Acc: 56.282 (721067/1281167) | Lr: 0.22425878935333746
[2022-06-18 03:28:53,915] Test: Loss: 1.541 | Acc: 62.862 (31431/50000)
[2022-06-18 03:28:53,916] Epoch: 280
[2022-06-18 03:47:05,483] Train: Loss: 1.928 | Acc: 56.287 (721125/1281167) | Lr: 0.22236058056446906
[2022-06-18 03:47:54,517] Test: Loss: 1.500 | Acc: 63.820 (31910/50000)
[2022-06-18 03:47:54,518] Saving..
[2022-06-18 03:47:54,601] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 03:47:54,602] Epoch: 281
[2022-06-18 04:06:01,201] Train: Loss: 1.925 | Acc: 56.370 (722190/1281167) | Lr: 0.22046569780410857
[2022-06-18 04:06:50,385] Test: Loss: 1.634 | Acc: 60.450 (30225/50000)
[2022-06-18 04:06:50,386] Epoch: 282
[2022-06-18 04:24:54,006] Train: Loss: 1.921 | Acc: 56.486 (723680/1281167) | Lr: 0.2185742222427268
[2022-06-18 04:25:44,672] Test: Loss: 1.599 | Acc: 61.652 (30826/50000)
[2022-06-18 04:25:44,673] Epoch: 283
[2022-06-18 04:43:54,045] Train: Loss: 1.919 | Acc: 56.527 (724208/1281167) | Lr: 0.2166862349048415
[2022-06-18 04:44:42,317] Test: Loss: 1.597 | Acc: 61.274 (30637/50000)
[2022-06-18 04:44:42,318] Epoch: 284
[2022-06-18 05:03:00,628] Train: Loss: 1.914 | Acc: 56.488 (723702/1281167) | Lr: 0.21480181666554649
[2022-06-18 05:04:04,052] Test: Loss: 1.587 | Acc: 61.888 (30944/50000)
[2022-06-18 05:04:04,053] Epoch: 285
[2022-06-18 05:22:18,284] Train: Loss: 1.913 | Acc: 56.655 (725851/1281167) | Lr: 0.21292104824704733
[2022-06-18 05:23:16,003] Test: Loss: 1.601 | Acc: 61.244 (30622/50000)
[2022-06-18 05:23:16,004] Epoch: 286
[2022-06-18 05:41:36,287] Train: Loss: 1.907 | Acc: 56.701 (726434/1281167) | Lr: 0.21104401021520333
[2022-06-18 05:42:28,254] Test: Loss: 1.668 | Acc: 60.408 (30204/50000)
[2022-06-18 05:42:28,255] Epoch: 287
[2022-06-18 06:00:45,056] Train: Loss: 1.903 | Acc: 56.794 (727631/1281167) | Lr: 0.20917078297607666
[2022-06-18 06:01:34,363] Test: Loss: 1.484 | Acc: 63.838 (31919/50000)
[2022-06-18 06:01:34,364] Saving..
[2022-06-18 06:01:34,446] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 06:01:34,447] Epoch: 288
[2022-06-18 06:19:45,812] Train: Loss: 1.899 | Acc: 56.849 (728335/1281167) | Lr: 0.20730144677248746
[2022-06-18 06:20:35,663] Test: Loss: 1.540 | Acc: 62.962 (31481/50000)
[2022-06-18 06:20:35,664] Epoch: 289
[2022-06-18 06:38:44,072] Train: Loss: 1.899 | Acc: 56.909 (729099/1281167) | Lr: 0.20543608168057714
[2022-06-18 06:39:32,290] Test: Loss: 1.484 | Acc: 63.726 (31863/50000)
[2022-06-18 06:39:32,291] Epoch: 290
[2022-06-18 06:57:48,441] Train: Loss: 1.894 | Acc: 57.005 (730325/1281167) | Lr: 0.2035747676063779
[2022-06-18 06:58:39,199] Test: Loss: 1.664 | Acc: 60.222 (30111/50000)
[2022-06-18 06:58:39,200] Epoch: 291
[2022-06-18 07:16:58,968] Train: Loss: 1.892 | Acc: 57.048 (730880/1281167) | Lr: 0.2017175842823896
[2022-06-18 07:17:47,467] Test: Loss: 1.634 | Acc: 60.954 (30477/50000)
[2022-06-18 07:17:47,468] Epoch: 292
[2022-06-18 07:36:11,243] Train: Loss: 1.885 | Acc: 57.163 (732356/1281167) | Lr: 0.1998646112641647
[2022-06-18 07:37:00,827] Test: Loss: 1.525 | Acc: 62.958 (31479/50000)
[2022-06-18 07:37:00,827] Epoch: 293
[2022-06-18 07:55:12,873] Train: Loss: 1.883 | Acc: 57.209 (732937/1281167) | Lr: 0.1980159279269002
[2022-06-18 07:56:02,040] Test: Loss: 1.789 | Acc: 58.342 (29171/50000)
[2022-06-18 07:56:02,041] Epoch: 294
[2022-06-18 08:14:18,389] Train: Loss: 1.881 | Acc: 57.233 (733246/1281167) | Lr: 0.1961716134620373
[2022-06-18 08:15:06,743] Test: Loss: 1.556 | Acc: 62.668 (31334/50000)
[2022-06-18 08:15:06,744] Epoch: 295
[2022-06-18 08:33:20,277] Train: Loss: 1.880 | Acc: 57.242 (733368/1281167) | Lr: 0.19433174687386934
[2022-06-18 08:34:08,358] Test: Loss: 1.591 | Acc: 61.548 (30774/50000)
[2022-06-18 08:34:08,359] Epoch: 296
[2022-06-18 08:52:29,888] Train: Loss: 1.879 | Acc: 57.283 (733886/1281167) | Lr: 0.19249640697615744
[2022-06-18 08:53:19,573] Test: Loss: 1.591 | Acc: 61.770 (30885/50000)
[2022-06-18 08:53:19,574] Epoch: 297
[2022-06-18 09:11:42,314] Train: Loss: 1.872 | Acc: 57.401 (735401/1281167) | Lr: 0.1906656723887543
[2022-06-18 09:12:30,634] Test: Loss: 1.474 | Acc: 64.008 (32004/50000)
[2022-06-18 09:12:30,634] Saving..
[2022-06-18 09:12:30,714] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 09:12:30,715] Epoch: 298
[2022-06-18 09:30:52,888] Train: Loss: 1.864 | Acc: 57.520 (736926/1281167) | Lr: 0.1888396215342365
[2022-06-18 09:31:42,050] Test: Loss: 1.583 | Acc: 62.118 (31059/50000)
[2022-06-18 09:31:42,052] Epoch: 299
[2022-06-18 09:50:09,395] Train: Loss: 1.867 | Acc: 57.535 (737118/1281167) | Lr: 0.18701833263454504
[2022-06-18 09:51:04,840] Test: Loss: 1.426 | Acc: 65.018 (32509/50000)
[2022-06-18 09:51:04,841] Saving..
[2022-06-18 09:51:04,936] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 09:51:04,937] Epoch: 300
[2022-06-18 10:09:04,337] Train: Loss: 1.866 | Acc: 57.538 (737162/1281167) | Lr: 0.1852018837076347
[2022-06-18 10:09:59,131] Test: Loss: 1.452 | Acc: 64.570 (32285/50000)
[2022-06-18 10:09:59,132] Epoch: 301
[2022-06-18 10:28:22,874] Train: Loss: 1.864 | Acc: 57.623 (738246/1281167) | Lr: 0.1833903525641319
[2022-06-18 10:29:11,317] Test: Loss: 1.581 | Acc: 61.570 (30785/50000)
[2022-06-18 10:29:11,319] Epoch: 302
[2022-06-18 10:47:34,232] Train: Loss: 1.857 | Acc: 57.772 (740161/1281167) | Lr: 0.1815838168040016
[2022-06-18 10:48:28,579] Test: Loss: 1.574 | Acc: 62.182 (31091/50000)
[2022-06-18 10:48:28,580] Epoch: 303
[2022-06-18 11:06:33,464] Train: Loss: 1.852 | Acc: 57.854 (741212/1281167) | Lr: 0.17978235381322308
[2022-06-18 11:07:22,858] Test: Loss: 1.418 | Acc: 65.164 (32582/50000)
[2022-06-18 11:07:22,859] Saving..
[2022-06-18 11:07:22,948] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 11:07:22,949] Epoch: 304
[2022-06-18 11:25:23,202] Train: Loss: 1.847 | Acc: 57.915 (741989/1281167) | Lr: 0.17798604076047517
[2022-06-18 11:26:13,774] Test: Loss: 1.474 | Acc: 64.296 (32148/50000)
[2022-06-18 11:26:13,775] Epoch: 305
[2022-06-18 11:44:28,171] Train: Loss: 1.847 | Acc: 57.922 (742079/1281167) | Lr: 0.17619495459383036
[2022-06-18 11:45:16,627] Test: Loss: 1.440 | Acc: 64.914 (32457/50000)
[2022-06-18 11:45:16,628] Epoch: 306
[2022-06-18 12:03:21,707] Train: Loss: 1.844 | Acc: 58.043 (743629/1281167) | Lr: 0.17440917203745904
[2022-06-18 12:04:14,594] Test: Loss: 1.490 | Acc: 63.844 (31922/50000)
[2022-06-18 12:04:14,595] Epoch: 307
[2022-06-18 12:22:20,530] Train: Loss: 1.840 | Acc: 58.063 (743886/1281167) | Lr: 0.17262876958834228
[2022-06-18 12:23:12,260] Test: Loss: 1.571 | Acc: 62.072 (31036/50000)
[2022-06-18 12:23:12,261] Epoch: 308
[2022-06-18 12:41:13,283] Train: Loss: 1.836 | Acc: 58.095 (744297/1281167) | Lr: 0.1708538235129954
[2022-06-18 12:42:02,984] Test: Loss: 1.433 | Acc: 64.672 (32336/50000)
[2022-06-18 12:42:02,985] Epoch: 309
[2022-06-18 13:00:07,791] Train: Loss: 1.832 | Acc: 58.190 (745507/1281167) | Lr: 0.16908440984420062
[2022-06-18 13:00:57,405] Test: Loss: 1.434 | Acc: 65.030 (32515/50000)
[2022-06-18 13:00:57,406] Epoch: 310
[2022-06-18 13:19:10,898] Train: Loss: 1.831 | Acc: 58.230 (746021/1281167) | Lr: 0.16732060437775062
[2022-06-18 13:20:00,111] Test: Loss: 1.544 | Acc: 62.920 (31460/50000)
[2022-06-18 13:20:00,112] Epoch: 311
[2022-06-18 13:38:07,650] Train: Loss: 1.827 | Acc: 58.320 (747180/1281167) | Lr: 0.16556248266920107
[2022-06-18 13:38:57,573] Test: Loss: 1.469 | Acc: 64.064 (32032/50000)
[2022-06-18 13:38:57,574] Epoch: 312
[2022-06-18 13:57:03,431] Train: Loss: 1.825 | Acc: 58.390 (748074/1281167) | Lr: 0.16381012003063453
[2022-06-18 13:57:51,884] Test: Loss: 1.396 | Acc: 65.830 (32915/50000)
[2022-06-18 13:57:51,884] Saving..
[2022-06-18 13:57:51,979] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 13:57:51,980] Epoch: 313
[2022-06-18 14:15:58,967] Train: Loss: 1.815 | Acc: 58.560 (750246/1281167) | Lr: 0.16206359152743416
[2022-06-18 14:16:47,849] Test: Loss: 1.473 | Acc: 64.188 (32094/50000)
[2022-06-18 14:16:47,850] Epoch: 314
[2022-06-18 14:35:09,513] Train: Loss: 1.817 | Acc: 58.512 (749634/1281167) | Lr: 0.1603229719750681
[2022-06-18 14:36:12,753] Test: Loss: 1.426 | Acc: 65.144 (32572/50000)
[2022-06-18 14:36:12,754] Epoch: 315
[2022-06-18 14:54:28,595] Train: Loss: 1.812 | Acc: 58.599 (750747/1281167) | Lr: 0.1585883359358847
[2022-06-18 14:55:22,053] Test: Loss: 1.393 | Acc: 65.978 (32989/50000)
[2022-06-18 14:55:22,053] Saving..
[2022-06-18 14:55:22,135] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 14:55:22,136] Epoch: 316
[2022-06-18 15:13:30,676] Train: Loss: 1.807 | Acc: 58.687 (751882/1281167) | Lr: 0.15685975771591865
[2022-06-18 15:14:19,972] Test: Loss: 1.750 | Acc: 58.230 (29115/50000)
[2022-06-18 15:14:19,973] Epoch: 317
[2022-06-18 15:32:30,328] Train: Loss: 1.806 | Acc: 58.681 (751808/1281167) | Lr: 0.15513731136170764
[2022-06-18 15:33:18,017] Test: Loss: 1.470 | Acc: 64.476 (32238/50000)
[2022-06-18 15:33:18,018] Epoch: 318
[2022-06-18 15:50:54,867] Train: Loss: 1.805 | Acc: 58.745 (752623/1281167) | Lr: 0.15342107065712082
[2022-06-18 15:51:42,918] Test: Loss: 1.496 | Acc: 63.700 (31850/50000)
[2022-06-18 15:51:42,918] Epoch: 319
[2022-06-18 16:09:23,824] Train: Loss: 1.798 | Acc: 58.915 (754803/1281167) | Lr: 0.151711109120198
[2022-06-18 16:10:12,746] Test: Loss: 1.385 | Acc: 66.024 (33012/50000)
[2022-06-18 16:10:12,747] Saving..
[2022-06-18 16:10:12,836] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 16:10:12,837] Epoch: 320
[2022-06-18 16:27:49,769] Train: Loss: 1.796 | Acc: 58.906 (754690/1281167) | Lr: 0.15000749999999993
[2022-06-18 16:28:37,889] Test: Loss: 1.430 | Acc: 64.826 (32413/50000)
[2022-06-18 16:28:37,890] Epoch: 321
[2022-06-18 16:46:22,591] Train: Loss: 1.790 | Acc: 59.054 (756586/1281167) | Lr: 0.14831031627347144
[2022-06-18 16:47:11,391] Test: Loss: 1.567 | Acc: 62.120 (31060/50000)
[2022-06-18 16:47:11,392] Epoch: 322
[2022-06-18 17:04:54,476] Train: Loss: 1.789 | Acc: 59.118 (757405/1281167) | Lr: 0.1466196306423147
[2022-06-18 17:05:42,994] Test: Loss: 1.415 | Acc: 65.460 (32730/50000)
[2022-06-18 17:05:42,996] Epoch: 323
[2022-06-18 17:23:17,882] Train: Loss: 1.783 | Acc: 59.243 (759001/1281167) | Lr: 0.14493551552987505
[2022-06-18 17:24:07,097] Test: Loss: 1.425 | Acc: 65.230 (32615/50000)
[2022-06-18 17:24:07,098] Epoch: 324
[2022-06-18 17:41:41,723] Train: Loss: 1.783 | Acc: 59.210 (758576/1281167) | Lr: 0.14325804307803883
[2022-06-18 17:42:31,670] Test: Loss: 1.387 | Acc: 66.024 (33012/50000)
[2022-06-18 17:42:31,671] Epoch: 325
[2022-06-18 18:00:12,252] Train: Loss: 1.777 | Acc: 59.326 (760069/1281167) | Lr: 0.14158728514414276
[2022-06-18 18:01:00,584] Test: Loss: 1.433 | Acc: 65.136 (32568/50000)
[2022-06-18 18:01:00,585] Epoch: 326
[2022-06-18 18:18:39,428] Train: Loss: 1.774 | Acc: 59.401 (761029/1281167) | Lr: 0.13992331329789603
[2022-06-18 18:19:28,956] Test: Loss: 1.371 | Acc: 66.270 (33135/50000)
[2022-06-18 18:19:28,957] Saving..
[2022-06-18 18:19:29,038] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 18:19:29,039] Epoch: 327
[2022-06-18 18:37:08,542] Train: Loss: 1.773 | Acc: 59.445 (761594/1281167) | Lr: 0.13826619881831437
[2022-06-18 18:37:56,712] Test: Loss: 1.408 | Acc: 65.636 (32818/50000)
[2022-06-18 18:37:56,713] Epoch: 328
[2022-06-18 18:55:41,905] Train: Loss: 1.769 | Acc: 59.490 (762163/1281167) | Lr: 0.13661601269066695
[2022-06-18 18:56:31,106] Test: Loss: 1.356 | Acc: 67.014 (33507/50000)
[2022-06-18 18:56:31,107] Saving..
[2022-06-18 18:56:31,204] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 18:56:31,205] Epoch: 329
[2022-06-18 19:14:08,749] Train: Loss: 1.763 | Acc: 59.564 (763117/1281167) | Lr: 0.13497282560343488
[2022-06-18 19:14:57,211] Test: Loss: 1.365 | Acc: 66.488 (33244/50000)
[2022-06-18 19:14:57,213] Epoch: 330
[2022-06-18 19:32:34,897] Train: Loss: 1.763 | Acc: 59.587 (763405/1281167) | Lr: 0.1333367079452844
[2022-06-18 19:33:23,151] Test: Loss: 1.443 | Acc: 64.638 (32319/50000)
[2022-06-18 19:33:23,152] Epoch: 331
[2022-06-18 19:51:04,523] Train: Loss: 1.757 | Acc: 59.721 (765126/1281167) | Lr: 0.13170772980205034
[2022-06-18 19:51:53,365] Test: Loss: 1.299 | Acc: 67.794 (33897/50000)
[2022-06-18 19:51:53,366] Saving..
[2022-06-18 19:51:53,440] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-18 19:51:53,440] Epoch: 332
[2022-06-18 20:09:34,438] Train: Loss: 1.752 | Acc: 59.828 (766492/1281167) | Lr: 0.13008596095373462
[2022-06-18 20:10:22,410] Test: Loss: 1.364 | Acc: 66.574 (33287/50000)
[2022-06-18 20:10:22,411] Epoch: 333
[2022-06-18 20:29:31,061] Train: Loss: 1.753 | Acc: 59.843 (766686/1281167) | Lr: 0.12847147087151742
[2022-06-18 20:30:19,587] Test: Loss: 1.363 | Acc: 66.770 (33385/50000)
[2022-06-18 20:30:19,589] Epoch: 334
[2022-06-18 20:48:00,663] Train: Loss: 1.744 | Acc: 59.969 (768304/1281167) | Lr: 0.12686432871477996
[2022-06-18 20:48:48,601] Test: Loss: 1.348 | Acc: 66.878 (33439/50000)
[2022-06-18 20:48:48,602] Epoch: 335
[2022-06-18 21:06:40,767] Train: Loss: 1.742 | Acc: 60.042 (769233/1281167) | Lr: 0.12526460332814365
[2022-06-18 21:07:28,391] Test: Loss: 1.302 | Acc: 67.694 (33847/50000)
[2022-06-18 21:07:28,391] Epoch: 336
[2022-06-18 21:25:16,536] Train: Loss: 1.735 | Acc: 60.159 (770732/1281167) | Lr: 0.12367236323851946
[2022-06-18 21:26:05,318] Test: Loss: 1.360 | Acc: 66.524 (33262/50000)
[2022-06-18 21:26:05,319] Epoch: 337
[2022-06-18 21:43:45,841] Train: Loss: 1.730 | Acc: 60.325 (772860/1281167) | Lr: 0.12208767665217356
[2022-06-18 21:44:34,057] Test: Loss: 1.356 | Acc: 66.848 (33424/50000)
[2022-06-18 21:44:34,058] Epoch: 338
[2022-06-18 22:02:22,649] Train: Loss: 1.734 | Acc: 60.183 (771042/1281167) | Lr: 0.12051061145180504
[2022-06-18 22:03:11,352] Test: Loss: 1.439 | Acc: 65.142 (32571/50000)
[2022-06-18 22:03:11,353] Epoch: 339
[2022-06-18 22:20:55,869] Train: Loss: 1.726 | Acc: 60.330 (772928/1281167) | Lr: 0.11894123519363835
[2022-06-18 22:21:43,396] Test: Loss: 1.322 | Acc: 67.232 (33616/50000)
[2022-06-18 22:21:43,397] Epoch: 340
[2022-06-18 22:39:29,200] Train: Loss: 1.724 | Acc: 60.377 (773529/1281167) | Lr: 0.11737961510452875
[2022-06-18 22:40:17,984] Test: Loss: 1.324 | Acc: 67.540 (33770/50000)
[2022-06-18 22:40:17,986] Epoch: 341
[2022-06-18 22:58:09,002] Train: Loss: 1.722 | Acc: 60.406 (773902/1281167) | Lr: 0.1158258180790838
[2022-06-18 22:58:57,970] Test: Loss: 1.354 | Acc: 66.680 (33340/50000)
[2022-06-18 22:58:57,971] Epoch: 342
[2022-06-18 23:16:42,004] Train: Loss: 1.713 | Acc: 60.625 (776707/1281167) | Lr: 0.11427991067679634
[2022-06-18 23:17:29,758] Test: Loss: 1.413 | Acc: 65.200 (32600/50000)
[2022-06-18 23:17:29,759] Epoch: 343
[2022-06-18 23:35:03,695] Train: Loss: 1.708 | Acc: 60.708 (777775/1281167) | Lr: 0.1127419591191943
[2022-06-18 23:35:53,071] Test: Loss: 1.372 | Acc: 66.216 (33108/50000)
[2022-06-18 23:35:53,072] Epoch: 344
[2022-06-18 23:53:31,350] Train: Loss: 1.706 | Acc: 60.783 (778734/1281167) | Lr: 0.11121202928700398
[2022-06-18 23:54:20,704] Test: Loss: 1.328 | Acc: 67.378 (33689/50000)
[2022-06-18 23:54:20,705] Epoch: 345
[2022-06-19 00:12:08,885] Train: Loss: 1.707 | Acc: 60.744 (778237/1281167) | Lr: 0.10969018671732703
[2022-06-19 00:12:57,586] Test: Loss: 1.297 | Acc: 67.788 (33894/50000)
[2022-06-19 00:12:57,588] Epoch: 346
[2022-06-19 00:30:52,373] Train: Loss: 1.701 | Acc: 60.864 (779767/1281167) | Lr: 0.10817649660083442
[2022-06-19 00:31:41,084] Test: Loss: 1.376 | Acc: 66.348 (33174/50000)
[2022-06-19 00:31:41,085] Epoch: 347
[2022-06-19 00:49:31,660] Train: Loss: 1.696 | Acc: 60.881 (779993/1281167) | Lr: 0.10667102377897254
[2022-06-19 00:50:19,663] Test: Loss: 1.318 | Acc: 67.684 (33842/50000)
[2022-06-19 00:50:19,665] Epoch: 348
[2022-06-19 01:08:01,299] Train: Loss: 1.691 | Acc: 61.055 (782218/1281167) | Lr: 0.10517383274118651
[2022-06-19 01:08:50,005] Test: Loss: 1.283 | Acc: 68.174 (34087/50000)
[2022-06-19 01:08:50,005] Saving..
[2022-06-19 01:08:50,169] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 01:08:50,170] Epoch: 349
[2022-06-19 01:26:31,738] Train: Loss: 1.689 | Acc: 61.105 (782861/1281167) | Lr: 0.10368498762215736
[2022-06-19 01:27:19,571] Test: Loss: 1.305 | Acc: 68.146 (34073/50000)
[2022-06-19 01:27:19,572] Epoch: 350
[2022-06-19 01:45:10,504] Train: Loss: 1.683 | Acc: 61.199 (784056/1281167) | Lr: 0.10220455219905486
[2022-06-19 01:45:59,343] Test: Loss: 1.297 | Acc: 67.990 (33995/50000)
[2022-06-19 01:45:59,343] Epoch: 351
[2022-06-19 02:03:36,196] Train: Loss: 1.678 | Acc: 61.313 (785521/1281167) | Lr: 0.10073258988880494
[2022-06-19 02:04:24,985] Test: Loss: 1.395 | Acc: 65.920 (32960/50000)
[2022-06-19 02:04:24,986] Epoch: 352
[2022-06-19 02:22:06,108] Train: Loss: 1.674 | Acc: 61.422 (786917/1281167) | Lr: 0.09926916374537434
[2022-06-19 02:22:54,966] Test: Loss: 1.300 | Acc: 68.146 (34073/50000)
[2022-06-19 02:22:54,967] Epoch: 353
[2022-06-19 02:40:36,135] Train: Loss: 1.674 | Acc: 61.355 (786057/1281167) | Lr: 0.09781433645706791
[2022-06-19 02:41:24,932] Test: Loss: 1.363 | Acc: 66.778 (33389/50000)
[2022-06-19 02:41:24,933] Epoch: 354
[2022-06-19 02:59:08,896] Train: Loss: 1.668 | Acc: 61.579 (788931/1281167) | Lr: 0.09636817034384504
[2022-06-19 02:59:58,161] Test: Loss: 1.276 | Acc: 68.596 (34298/50000)
[2022-06-19 02:59:58,161] Saving..
[2022-06-19 02:59:58,248] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 02:59:58,249] Epoch: 355
[2022-06-19 03:17:37,731] Train: Loss: 1.665 | Acc: 61.610 (789324/1281167) | Lr: 0.09493072735464868
[2022-06-19 03:18:26,421] Test: Loss: 1.468 | Acc: 64.416 (32208/50000)
[2022-06-19 03:18:26,423] Epoch: 356
[2022-06-19 03:36:23,758] Train: Loss: 1.663 | Acc: 61.664 (790022/1281167) | Lr: 0.09350206906475214
[2022-06-19 03:37:11,563] Test: Loss: 1.284 | Acc: 68.260 (34130/50000)
[2022-06-19 03:37:11,564] Epoch: 357
[2022-06-19 03:55:07,975] Train: Loss: 1.657 | Acc: 61.726 (790810/1281167) | Lr: 0.09208225667312192
[2022-06-19 03:55:56,813] Test: Loss: 1.418 | Acc: 65.544 (32772/50000)
[2022-06-19 03:55:56,815] Epoch: 358
[2022-06-19 04:13:43,638] Train: Loss: 1.652 | Acc: 61.857 (792487/1281167) | Lr: 0.09067135099979513
[2022-06-19 04:14:32,577] Test: Loss: 1.396 | Acc: 65.706 (32853/50000)
[2022-06-19 04:14:32,578] Epoch: 359
[2022-06-19 04:32:25,048] Train: Loss: 1.648 | Acc: 61.936 (793499/1281167) | Lr: 0.08926941248327502
[2022-06-19 04:33:13,418] Test: Loss: 1.262 | Acc: 68.880 (34440/50000)
[2022-06-19 04:33:13,418] Saving..
[2022-06-19 04:33:13,494] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 04:33:13,495] Epoch: 360
[2022-06-19 04:50:54,944] Train: Loss: 1.644 | Acc: 61.957 (793779/1281167) | Lr: 0.08787650117794162
[2022-06-19 04:51:43,493] Test: Loss: 1.241 | Acc: 69.190 (34595/50000)
[2022-06-19 04:51:43,493] Saving..
[2022-06-19 04:51:43,579] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 04:51:43,580] Epoch: 361
[2022-06-19 05:09:33,636] Train: Loss: 1.642 | Acc: 62.031 (794716/1281167) | Lr: 0.08649267675147938
[2022-06-19 05:10:21,436] Test: Loss: 1.243 | Acc: 69.170 (34585/50000)
[2022-06-19 05:10:21,437] Epoch: 362
[2022-06-19 05:28:00,507] Train: Loss: 1.639 | Acc: 62.158 (796344/1281167) | Lr: 0.08511799848232077
[2022-06-19 05:28:49,875] Test: Loss: 1.245 | Acc: 69.150 (34575/50000)
[2022-06-19 05:28:49,876] Epoch: 363
[2022-06-19 05:46:31,750] Train: Loss: 1.633 | Acc: 62.227 (797232/1281167) | Lr: 0.08375252525710779
[2022-06-19 05:47:21,642] Test: Loss: 1.294 | Acc: 68.166 (34083/50000)
[2022-06-19 05:47:21,643] Epoch: 364
[2022-06-19 06:04:59,156] Train: Loss: 1.629 | Acc: 62.343 (798715/1281167) | Lr: 0.08239631556816869
[2022-06-19 06:05:47,954] Test: Loss: 1.312 | Acc: 67.750 (33875/50000)
[2022-06-19 06:05:47,955] Epoch: 365
[2022-06-19 06:23:27,484] Train: Loss: 1.625 | Acc: 62.419 (799686/1281167) | Lr: 0.0810494275110127
[2022-06-19 06:24:16,896] Test: Loss: 1.282 | Acc: 68.354 (34177/50000)
[2022-06-19 06:24:16,897] Epoch: 366
[2022-06-19 06:42:08,421] Train: Loss: 1.620 | Acc: 62.520 (800987/1281167) | Lr: 0.0797119187818415
[2022-06-19 06:42:58,249] Test: Loss: 1.233 | Acc: 69.200 (34600/50000)
[2022-06-19 06:42:58,250] Saving..
[2022-06-19 06:42:58,331] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 06:42:58,332] Epoch: 367
[2022-06-19 07:00:36,751] Train: Loss: 1.616 | Acc: 62.569 (801607/1281167) | Lr: 0.07838384667507721
[2022-06-19 07:01:26,738] Test: Loss: 1.230 | Acc: 69.570 (34785/50000)
[2022-06-19 07:01:26,738] Saving..
[2022-06-19 07:01:26,814] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 07:01:26,815] Epoch: 368
[2022-06-19 07:19:04,276] Train: Loss: 1.609 | Acc: 62.753 (803975/1281167) | Lr: 0.07706526808090909
[2022-06-19 07:19:53,179] Test: Loss: 1.252 | Acc: 68.954 (34477/50000)
[2022-06-19 07:19:53,180] Epoch: 369
[2022-06-19 07:37:27,625] Train: Loss: 1.604 | Acc: 62.831 (804975/1281167) | Lr: 0.07575623948285524
[2022-06-19 07:38:17,772] Test: Loss: 1.287 | Acc: 68.210 (34105/50000)
[2022-06-19 07:38:17,773] Epoch: 370
[2022-06-19 07:56:04,475] Train: Loss: 1.603 | Acc: 62.878 (805571/1281167) | Lr: 0.07445681695534413
[2022-06-19 07:56:53,885] Test: Loss: 1.379 | Acc: 66.178 (33089/50000)
[2022-06-19 07:56:53,885] Epoch: 371
[2022-06-19 08:14:34,800] Train: Loss: 1.599 | Acc: 62.927 (806203/1281167) | Lr: 0.073167056161312
[2022-06-19 08:15:22,998] Test: Loss: 1.296 | Acc: 68.132 (34066/50000)
[2022-06-19 08:15:22,999] Epoch: 372
[2022-06-19 08:33:07,417] Train: Loss: 1.593 | Acc: 63.025 (807459/1281167) | Lr: 0.07188701234981865
[2022-06-19 08:33:56,759] Test: Loss: 1.222 | Acc: 69.682 (34841/50000)
[2022-06-19 08:33:56,759] Saving..
[2022-06-19 08:33:56,842] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 08:33:56,843] Epoch: 373
[2022-06-19 08:51:40,503] Train: Loss: 1.591 | Acc: 63.155 (809115/1281167) | Lr: 0.07061674035368062
[2022-06-19 08:52:29,538] Test: Loss: 1.197 | Acc: 70.236 (35118/50000)
[2022-06-19 08:52:29,539] Saving..
[2022-06-19 08:52:29,629] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 08:52:29,630] Epoch: 374
[2022-06-19 09:10:05,141] Train: Loss: 1.581 | Acc: 63.320 (811232/1281167) | Lr: 0.06935629458712246
[2022-06-19 09:10:56,222] Test: Loss: 1.216 | Acc: 69.812 (34906/50000)
[2022-06-19 09:10:56,223] Epoch: 375
[2022-06-19 09:28:37,782] Train: Loss: 1.583 | Acc: 63.269 (810579/1281167) | Lr: 0.06810572904344565
[2022-06-19 09:29:26,293] Test: Loss: 1.270 | Acc: 68.636 (34318/50000)
[2022-06-19 09:29:26,294] Epoch: 376
[2022-06-19 09:47:09,210] Train: Loss: 1.575 | Acc: 63.443 (812815/1281167) | Lr: 0.06686509729271595
[2022-06-19 09:48:00,307] Test: Loss: 1.269 | Acc: 68.588 (34294/50000)
[2022-06-19 09:48:00,308] Epoch: 377
[2022-06-19 10:05:46,491] Train: Loss: 1.571 | Acc: 63.530 (813927/1281167) | Lr: 0.06563445247946846
[2022-06-19 10:06:34,550] Test: Loss: 1.224 | Acc: 69.540 (34770/50000)
[2022-06-19 10:06:34,552] Epoch: 378
[2022-06-19 10:24:08,755] Train: Loss: 1.564 | Acc: 63.654 (815520/1281167) | Lr: 0.06441384732043082
[2022-06-19 10:24:57,498] Test: Loss: 1.258 | Acc: 69.104 (34552/50000)
[2022-06-19 10:24:57,500] Epoch: 379
[2022-06-19 10:42:44,078] Train: Loss: 1.563 | Acc: 63.676 (815799/1281167) | Lr: 0.06320333410226592
[2022-06-19 10:43:32,546] Test: Loss: 1.219 | Acc: 69.788 (34894/50000)
[2022-06-19 10:43:32,547] Epoch: 380
[2022-06-19 11:01:10,650] Train: Loss: 1.557 | Acc: 63.852 (818048/1281167) | Lr: 0.06200296467933081
[2022-06-19 11:01:59,129] Test: Loss: 1.218 | Acc: 69.984 (34992/50000)
[2022-06-19 11:01:59,130] Epoch: 381
[2022-06-19 11:19:49,144] Train: Loss: 1.551 | Acc: 63.940 (819175/1281167) | Lr: 0.0608127904714567
[2022-06-19 11:20:37,727] Test: Loss: 1.186 | Acc: 70.600 (35300/50000)
[2022-06-19 11:20:37,727] Saving..
[2022-06-19 11:20:37,820] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 11:20:37,821] Epoch: 382
[2022-06-19 11:38:13,296] Train: Loss: 1.547 | Acc: 64.012 (820104/1281167) | Lr: 0.05963286246174523
[2022-06-19 11:39:01,620] Test: Loss: 1.289 | Acc: 68.556 (34278/50000)
[2022-06-19 11:39:01,621] Epoch: 383
[2022-06-19 11:56:38,055] Train: Loss: 1.548 | Acc: 64.030 (820331/1281167) | Lr: 0.0584632311943853
[2022-06-19 11:57:25,887] Test: Loss: 1.171 | Acc: 71.038 (35519/50000)
[2022-06-19 11:57:25,887] Saving..
[2022-06-19 11:57:25,974] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 11:57:25,975] Epoch: 384
[2022-06-19 12:15:04,472] Train: Loss: 1.539 | Acc: 64.150 (821870/1281167) | Lr: 0.05730394677248761
[2022-06-19 12:15:53,945] Test: Loss: 1.238 | Acc: 69.570 (34785/50000)
[2022-06-19 12:15:53,946] Epoch: 385
[2022-06-19 12:33:33,600] Train: Loss: 1.539 | Acc: 64.210 (822631/1281167) | Lr: 0.056155058855938356
[2022-06-19 12:34:22,568] Test: Loss: 1.196 | Acc: 70.388 (35194/50000)
[2022-06-19 12:34:22,570] Epoch: 386
[2022-06-19 12:51:54,082] Train: Loss: 1.532 | Acc: 64.360 (824554/1281167) | Lr: 0.05501661665927207
[2022-06-19 12:52:43,397] Test: Loss: 1.150 | Acc: 71.476 (35738/50000)
[2022-06-19 12:52:43,397] Saving..
[2022-06-19 12:52:43,500] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 12:52:43,501] Epoch: 387
[2022-06-19 13:10:22,643] Train: Loss: 1.526 | Acc: 64.446 (825666/1281167) | Lr: 0.05388866894956349
[2022-06-19 13:11:11,368] Test: Loss: 1.223 | Acc: 69.946 (34973/50000)
[2022-06-19 13:11:11,369] Epoch: 388
[2022-06-19 13:29:02,395] Train: Loss: 1.520 | Acc: 64.576 (827321/1281167) | Lr: 0.052771264044338406
[2022-06-19 13:29:51,075] Test: Loss: 1.184 | Acc: 70.840 (35420/50000)
[2022-06-19 13:29:51,076] Epoch: 389
[2022-06-19 13:47:29,220] Train: Loss: 1.519 | Acc: 64.615 (827821/1281167) | Lr: 0.05166444980950378
[2022-06-19 13:48:17,694] Test: Loss: 1.223 | Acc: 69.776 (34888/50000)
[2022-06-19 13:48:17,695] Epoch: 390
[2022-06-19 14:05:56,052] Train: Loss: 1.508 | Acc: 64.812 (830346/1281167) | Lr: 0.050568273657297956
[2022-06-19 14:06:44,526] Test: Loss: 1.193 | Acc: 70.434 (35217/50000)
[2022-06-19 14:06:44,527] Epoch: 391
[2022-06-19 14:24:28,672] Train: Loss: 1.502 | Acc: 64.978 (832476/1281167) | Lr: 0.04948278254425858
[2022-06-19 14:25:17,407] Test: Loss: 1.173 | Acc: 70.700 (35350/50000)
[2022-06-19 14:25:17,408] Epoch: 392
[2022-06-19 14:42:59,589] Train: Loss: 1.501 | Acc: 64.969 (832366/1281167) | Lr: 0.04840802296921249
[2022-06-19 14:43:48,031] Test: Loss: 1.155 | Acc: 71.332 (35666/50000)
[2022-06-19 14:43:48,032] Epoch: 393
[2022-06-19 15:01:36,268] Train: Loss: 1.499 | Acc: 65.019 (833004/1281167) | Lr: 0.0473440409712826
[2022-06-19 15:02:24,410] Test: Loss: 1.147 | Acc: 71.444 (35722/50000)
[2022-06-19 15:02:24,412] Epoch: 394
[2022-06-19 15:20:08,480] Train: Loss: 1.494 | Acc: 65.152 (834706/1281167) | Lr: 0.04629088212791651
[2022-06-19 15:20:56,890] Test: Loss: 1.132 | Acc: 71.816 (35908/50000)
[2022-06-19 15:20:56,891] Saving..
[2022-06-19 15:20:56,989] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 15:20:56,990] Epoch: 395
[2022-06-19 15:38:41,436] Train: Loss: 1.492 | Acc: 65.119 (834283/1281167) | Lr: 0.04524859155293395
[2022-06-19 15:39:29,794] Test: Loss: 1.184 | Acc: 70.674 (35337/50000)
[2022-06-19 15:39:29,795] Epoch: 396
[2022-06-19 15:57:19,139] Train: Loss: 1.481 | Acc: 65.362 (837402/1281167) | Lr: 0.04421721389459408
[2022-06-19 15:58:09,594] Test: Loss: 1.148 | Acc: 71.526 (35763/50000)
[2022-06-19 15:58:09,595] Epoch: 397
[2022-06-19 16:15:49,623] Train: Loss: 1.476 | Acc: 65.479 (838889/1281167) | Lr: 0.04319679333368313
[2022-06-19 16:16:38,299] Test: Loss: 1.134 | Acc: 71.832 (35916/50000)
[2022-06-19 16:16:38,299] Saving..
[2022-06-19 16:16:38,380] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 16:16:38,381] Epoch: 398
[2022-06-19 16:34:25,122] Train: Loss: 1.475 | Acc: 65.486 (838986/1281167) | Lr: 0.04218737358162167
[2022-06-19 16:35:14,655] Test: Loss: 1.128 | Acc: 71.960 (35980/50000)
[2022-06-19 16:35:14,656] Saving..
[2022-06-19 16:35:14,735] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 16:35:14,736] Epoch: 399
[2022-06-19 16:53:01,122] Train: Loss: 1.470 | Acc: 65.659 (841201/1281167) | Lr: 0.04118899787859231
[2022-06-19 16:53:49,385] Test: Loss: 1.139 | Acc: 71.698 (35849/50000)
[2022-06-19 16:53:49,386] Epoch: 400
[2022-06-19 17:11:25,235] Train: Loss: 1.463 | Acc: 65.769 (842607/1281167) | Lr: 0.040201708991687284
[2022-06-19 17:12:14,661] Test: Loss: 1.137 | Acc: 71.840 (35920/50000)
[2022-06-19 17:12:14,662] Epoch: 401
[2022-06-19 17:30:02,584] Train: Loss: 1.459 | Acc: 65.860 (843773/1281167) | Lr: 0.039225549213076645
[2022-06-19 17:30:51,095] Test: Loss: 1.113 | Acc: 72.096 (36048/50000)
[2022-06-19 17:30:51,095] Saving..
[2022-06-19 17:30:51,174] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 17:30:51,175] Epoch: 402
[2022-06-19 17:48:34,819] Train: Loss: 1.454 | Acc: 65.955 (844996/1281167) | Lr: 0.03826056035819619
[2022-06-19 17:49:24,309] Test: Loss: 1.114 | Acc: 72.244 (36122/50000)
[2022-06-19 17:49:24,310] Saving..
[2022-06-19 17:49:24,392] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 17:49:24,393] Epoch: 403
[2022-06-19 18:07:03,044] Train: Loss: 1.449 | Acc: 66.096 (846803/1281167) | Lr: 0.037306783763956984
[2022-06-19 18:07:52,325] Test: Loss: 1.158 | Acc: 71.170 (35585/50000)
[2022-06-19 18:07:52,326] Epoch: 404
[2022-06-19 18:25:31,789] Train: Loss: 1.442 | Acc: 66.253 (848807/1281167) | Lr: 0.036364260286973704
[2022-06-19 18:26:20,967] Test: Loss: 1.164 | Acc: 71.076 (35538/50000)
[2022-06-19 18:26:20,968] Epoch: 405
[2022-06-19 18:44:11,980] Train: Loss: 1.437 | Acc: 66.328 (849768/1281167) | Lr: 0.03543303030181524
[2022-06-19 18:45:00,689] Test: Loss: 1.117 | Acc: 72.120 (36060/50000)
[2022-06-19 18:45:00,690] Epoch: 406
[2022-06-19 19:02:53,467] Train: Loss: 1.431 | Acc: 66.431 (851092/1281167) | Lr: 0.034513133699274764
[2022-06-19 19:03:43,093] Test: Loss: 1.132 | Acc: 71.724 (35862/50000)
[2022-06-19 19:03:43,094] Epoch: 407
[2022-06-19 19:21:32,369] Train: Loss: 1.433 | Acc: 66.409 (850813/1281167) | Lr: 0.03360460988466101
[2022-06-19 19:22:21,577] Test: Loss: 1.120 | Acc: 72.164 (36082/50000)
[2022-06-19 19:22:21,578] Epoch: 408
[2022-06-19 19:40:02,154] Train: Loss: 1.422 | Acc: 66.630 (853639/1281167) | Lr: 0.03270749777611059
[2022-06-19 19:40:52,072] Test: Loss: 1.103 | Acc: 72.372 (36186/50000)
[2022-06-19 19:40:52,072] Saving..
[2022-06-19 19:40:52,156] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 19:40:52,157] Epoch: 409
[2022-06-19 19:58:30,314] Train: Loss: 1.421 | Acc: 66.684 (854335/1281167) | Lr: 0.0318218358029202
[2022-06-19 19:59:20,893] Test: Loss: 1.111 | Acc: 72.424 (36212/50000)
[2022-06-19 19:59:20,894] Saving..
[2022-06-19 19:59:21,067] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 19:59:21,069] Epoch: 410
[2022-06-19 20:17:00,958] Train: Loss: 1.416 | Acc: 66.821 (856091/1281167) | Lr: 0.030947661903901174
[2022-06-19 20:17:50,209] Test: Loss: 1.137 | Acc: 71.880 (35940/50000)
[2022-06-19 20:17:50,210] Epoch: 411
[2022-06-19 20:35:28,902] Train: Loss: 1.406 | Acc: 66.973 (858032/1281167) | Lr: 0.030085013525753792
[2022-06-19 20:36:17,522] Test: Loss: 1.088 | Acc: 72.958 (36479/50000)
[2022-06-19 20:36:17,522] Saving..
[2022-06-19 20:36:17,599] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 20:36:17,600] Epoch: 412
[2022-06-19 20:54:00,374] Train: Loss: 1.402 | Acc: 67.045 (858953/1281167) | Lr: 0.029233927621463613
[2022-06-19 20:54:49,232] Test: Loss: 1.102 | Acc: 72.410 (36205/50000)
[2022-06-19 20:54:49,233] Epoch: 413
[2022-06-19 21:12:27,956] Train: Loss: 1.393 | Acc: 67.272 (861868/1281167) | Lr: 0.02839444064871788
[2022-06-19 21:13:16,042] Test: Loss: 1.098 | Acc: 72.526 (36263/50000)
[2022-06-19 21:13:16,042] Epoch: 414
[2022-06-19 21:30:58,819] Train: Loss: 1.393 | Acc: 67.270 (861839/1281167) | Lr: 0.02756658856834477
[2022-06-19 21:31:47,390] Test: Loss: 1.075 | Acc: 73.328 (36664/50000)
[2022-06-19 21:31:47,390] Saving..
[2022-06-19 21:31:47,478] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 21:31:47,479] Epoch: 415
[2022-06-19 21:49:25,793] Train: Loss: 1.387 | Acc: 67.364 (863047/1281167) | Lr: 0.026750406842771888
[2022-06-19 21:50:14,939] Test: Loss: 1.085 | Acc: 72.912 (36456/50000)
[2022-06-19 21:50:14,940] Epoch: 416
[2022-06-19 22:08:10,931] Train: Loss: 1.384 | Acc: 67.452 (864175/1281167) | Lr: 0.025945930434507904
[2022-06-19 22:08:59,535] Test: Loss: 1.067 | Acc: 73.310 (36655/50000)
[2022-06-19 22:08:59,537] Epoch: 417
[2022-06-19 22:26:41,843] Train: Loss: 1.373 | Acc: 67.704 (867396/1281167) | Lr: 0.025153193804644813
[2022-06-19 22:27:29,861] Test: Loss: 1.062 | Acc: 73.454 (36727/50000)
[2022-06-19 22:27:29,862] Saving..
[2022-06-19 22:27:29,935] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 22:27:29,936] Epoch: 418
[2022-06-19 22:45:15,797] Train: Loss: 1.368 | Acc: 67.766 (868190/1281167) | Lr: 0.024372230911381205
[2022-06-19 22:46:03,895] Test: Loss: 1.066 | Acc: 73.484 (36742/50000)
[2022-06-19 22:46:03,895] Saving..
[2022-06-19 22:46:03,977] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 22:46:03,978] Epoch: 419
[2022-06-19 23:03:54,658] Train: Loss: 1.364 | Acc: 67.902 (869941/1281167) | Lr: 0.02360307520856838
[2022-06-19 23:04:43,554] Test: Loss: 1.068 | Acc: 73.572 (36786/50000)
[2022-06-19 23:04:43,555] Saving..
[2022-06-19 23:04:43,701] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 23:04:43,702] Epoch: 420
[2022-06-19 23:22:36,105] Train: Loss: 1.358 | Acc: 68.019 (871432/1281167) | Lr: 0.02284575964427652
[2022-06-19 23:23:24,683] Test: Loss: 1.061 | Acc: 73.654 (36827/50000)
[2022-06-19 23:23:24,684] Saving..
[2022-06-19 23:23:24,766] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-19 23:23:24,767] Epoch: 421
[2022-06-19 23:41:01,869] Train: Loss: 1.352 | Acc: 68.124 (872776/1281167) | Lr: 0.02210031665938393
[2022-06-19 23:41:50,480] Test: Loss: 1.072 | Acc: 73.344 (36672/50000)
[2022-06-19 23:41:50,481] Epoch: 422
[2022-06-19 23:59:35,804] Train: Loss: 1.345 | Acc: 68.316 (875241/1281167) | Lr: 0.021366778186187076
[2022-06-20 00:00:24,477] Test: Loss: 1.074 | Acc: 73.292 (36646/50000)
[2022-06-20 00:00:24,478] Epoch: 423
[2022-06-20 00:18:05,208] Train: Loss: 1.340 | Acc: 68.361 (875820/1281167) | Lr: 0.02064517564703278
[2022-06-20 00:18:54,278] Test: Loss: 1.064 | Acc: 73.340 (36670/50000)
[2022-06-20 00:18:54,279] Epoch: 424
[2022-06-20 00:36:25,890] Train: Loss: 1.340 | Acc: 68.420 (876572/1281167) | Lr: 0.019935539952971953
[2022-06-20 00:37:15,783] Test: Loss: 1.061 | Acc: 73.472 (36736/50000)
[2022-06-20 00:37:15,784] Epoch: 425
[2022-06-20 00:55:03,784] Train: Loss: 1.333 | Acc: 68.557 (878334/1281167) | Lr: 0.019237901502436115
[2022-06-20 00:55:53,309] Test: Loss: 1.052 | Acc: 73.622 (36811/50000)
[2022-06-20 00:55:53,310] Epoch: 426
[2022-06-20 01:13:46,879] Train: Loss: 1.328 | Acc: 68.695 (880095/1281167) | Lr: 0.018552290179934355
[2022-06-20 01:14:36,597] Test: Loss: 1.044 | Acc: 74.012 (37006/50000)
[2022-06-20 01:14:36,598] Saving..
[2022-06-20 01:14:36,713] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 01:14:36,714] Epoch: 427
[2022-06-20 01:32:20,176] Train: Loss: 1.322 | Acc: 68.819 (881691/1281167) | Lr: 0.017878735354773998
[2022-06-20 01:33:09,381] Test: Loss: 1.030 | Acc: 74.338 (37169/50000)
[2022-06-20 01:33:09,381] Saving..
[2022-06-20 01:33:09,466] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 01:33:09,467] Epoch: 428
[2022-06-20 01:50:51,120] Train: Loss: 1.316 | Acc: 68.916 (882931/1281167) | Lr: 0.017217265879801952
[2022-06-20 01:51:40,130] Test: Loss: 1.030 | Acc: 74.292 (37146/50000)
[2022-06-20 01:51:40,131] Epoch: 429
[2022-06-20 02:09:24,415] Train: Loss: 1.310 | Acc: 69.046 (884594/1281167) | Lr: 0.01656791009016891
[2022-06-20 02:10:13,612] Test: Loss: 1.028 | Acc: 74.246 (37123/50000)
[2022-06-20 02:10:13,613] Epoch: 430
[2022-06-20 02:28:03,899] Train: Loss: 1.305 | Acc: 69.136 (885753/1281167) | Lr: 0.015930695802115792
[2022-06-20 02:28:51,559] Test: Loss: 1.040 | Acc: 74.178 (37089/50000)
[2022-06-20 02:28:51,560] Epoch: 431
[2022-06-20 02:46:51,162] Train: Loss: 1.298 | Acc: 69.277 (887560/1281167) | Lr: 0.015305650311781776
[2022-06-20 02:47:39,511] Test: Loss: 1.029 | Acc: 74.344 (37172/50000)
[2022-06-20 02:47:39,512] Saving..
[2022-06-20 02:47:39,584] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 02:47:39,585] Epoch: 432
[2022-06-20 03:05:26,989] Train: Loss: 1.292 | Acc: 69.398 (889106/1281167) | Lr: 0.014692800394035406
[2022-06-20 03:06:15,482] Test: Loss: 1.017 | Acc: 74.650 (37325/50000)
[2022-06-20 03:06:15,482] Saving..
[2022-06-20 03:06:15,556] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 03:06:15,557] Epoch: 433
[2022-06-20 03:23:57,093] Train: Loss: 1.288 | Acc: 69.529 (890780/1281167) | Lr: 0.01409217230132743
[2022-06-20 03:24:45,256] Test: Loss: 1.013 | Acc: 74.742 (37371/50000)
[2022-06-20 03:24:45,256] Saving..
[2022-06-20 03:24:45,336] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 03:24:45,337] Epoch: 434
[2022-06-20 03:42:34,515] Train: Loss: 1.283 | Acc: 69.686 (892799/1281167) | Lr: 0.01350379176256632
[2022-06-20 03:43:22,802] Test: Loss: 1.028 | Acc: 74.324 (37162/50000)
[2022-06-20 03:43:22,803] Epoch: 435
[2022-06-20 04:00:59,943] Train: Loss: 1.277 | Acc: 69.720 (893224/1281167) | Lr: 0.012927683982016004
[2022-06-20 04:01:48,801] Test: Loss: 1.011 | Acc: 74.774 (37387/50000)
[2022-06-20 04:01:48,801] Saving..
[2022-06-20 04:01:48,880] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 04:01:48,881] Epoch: 436
[2022-06-20 04:19:40,271] Train: Loss: 1.271 | Acc: 69.964 (896353/1281167) | Lr: 0.01236387363821645
[2022-06-20 04:20:28,130] Test: Loss: 1.009 | Acc: 74.840 (37420/50000)
[2022-06-20 04:20:28,130] Saving..
[2022-06-20 04:20:28,228] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 04:20:28,229] Epoch: 437
[2022-06-20 04:38:05,393] Train: Loss: 1.263 | Acc: 70.079 (897823/1281167) | Lr: 0.011812384882926191
[2022-06-20 04:38:53,927] Test: Loss: 1.006 | Acc: 74.854 (37427/50000)
[2022-06-20 04:38:53,927] Saving..
[2022-06-20 04:38:54,012] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 04:38:54,013] Epoch: 438
[2022-06-20 04:56:30,476] Train: Loss: 1.261 | Acc: 70.115 (898294/1281167) | Lr: 0.011273241340088076
[2022-06-20 04:57:20,695] Test: Loss: 1.016 | Acc: 74.756 (37378/50000)
[2022-06-20 04:57:20,696] Epoch: 439
[2022-06-20 05:15:06,023] Train: Loss: 1.254 | Acc: 70.267 (900237/1281167) | Lr: 0.01074646610481706
[2022-06-20 05:15:56,300] Test: Loss: 1.006 | Acc: 74.996 (37498/50000)
[2022-06-20 05:15:56,300] Saving..
[2022-06-20 05:15:56,387] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 05:15:56,388] Epoch: 440
[2022-06-20 05:33:42,983] Train: Loss: 1.250 | Acc: 70.405 (902012/1281167) | Lr: 0.010232081742410942
[2022-06-20 05:34:32,921] Test: Loss: 1.003 | Acc: 74.970 (37485/50000)
[2022-06-20 05:34:32,923] Epoch: 441
[2022-06-20 05:52:09,490] Train: Loss: 1.243 | Acc: 70.488 (903071/1281167) | Lr: 0.009730110287383863
[2022-06-20 05:52:59,288] Test: Loss: 1.003 | Acc: 75.032 (37516/50000)
[2022-06-20 05:52:59,288] Saving..
[2022-06-20 05:52:59,387] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 05:52:59,388] Epoch: 442
[2022-06-20 06:10:46,641] Train: Loss: 1.238 | Acc: 70.624 (904816/1281167) | Lr: 0.009240573242522235
[2022-06-20 06:11:35,576] Test: Loss: 1.000 | Acc: 75.112 (37556/50000)
[2022-06-20 06:11:35,577] Saving..
[2022-06-20 06:11:35,653] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 06:11:35,654] Epoch: 443
[2022-06-20 06:29:12,994] Train: Loss: 1.230 | Acc: 70.773 (906720/1281167) | Lr: 0.008763491577963696
[2022-06-20 06:30:01,965] Test: Loss: 0.993 | Acc: 75.206 (37603/50000)
[2022-06-20 06:30:01,965] Saving..
[2022-06-20 06:30:02,051] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 06:30:02,052] Epoch: 444
[2022-06-20 06:47:44,614] Train: Loss: 1.225 | Acc: 70.871 (907978/1281167) | Lr: 0.008298885730299011
[2022-06-20 06:48:33,429] Test: Loss: 0.985 | Acc: 75.316 (37658/50000)
[2022-06-20 06:48:33,429] Saving..
[2022-06-20 06:48:33,509] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 06:48:33,509] Epoch: 445
[2022-06-20 07:06:23,589] Train: Loss: 1.220 | Acc: 70.987 (909460/1281167) | Lr: 0.007846775601696289
[2022-06-20 07:07:12,658] Test: Loss: 0.994 | Acc: 75.104 (37552/50000)
[2022-06-20 07:07:12,659] Epoch: 446
[2022-06-20 07:24:52,795] Train: Loss: 1.213 | Acc: 71.155 (911615/1281167) | Lr: 0.007407180559048736
[2022-06-20 07:25:41,947] Test: Loss: 0.986 | Acc: 75.450 (37725/50000)
[2022-06-20 07:25:41,947] Saving..
[2022-06-20 07:25:42,035] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 07:25:42,036] Epoch: 447
[2022-06-20 07:43:32,659] Train: Loss: 1.210 | Acc: 71.242 (912726/1281167) | Lr: 0.006980119433144881
[2022-06-20 07:44:22,045] Test: Loss: 0.985 | Acc: 75.352 (37676/50000)
[2022-06-20 07:44:22,046] Epoch: 448
[2022-06-20 08:02:03,248] Train: Loss: 1.209 | Acc: 71.268 (913068/1281167) | Lr: 0.006565610517861955
[2022-06-20 08:02:53,419] Test: Loss: 0.978 | Acc: 75.704 (37852/50000)
[2022-06-20 08:02:53,419] Saving..
[2022-06-20 08:02:53,505] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 08:02:53,506] Epoch: 449
[2022-06-20 08:20:34,185] Train: Loss: 1.201 | Acc: 71.446 (915338/1281167) | Lr: 0.006163671569382373
[2022-06-20 08:21:23,850] Test: Loss: 0.976 | Acc: 75.572 (37786/50000)
[2022-06-20 08:21:23,851] Epoch: 450
[2022-06-20 08:39:08,409] Train: Loss: 1.199 | Acc: 71.485 (915846/1281167) | Lr: 0.005774319805432881
[2022-06-20 08:39:57,060] Test: Loss: 0.980 | Acc: 75.664 (37832/50000)
[2022-06-20 08:39:57,061] Epoch: 451
[2022-06-20 08:57:43,362] Train: Loss: 1.193 | Acc: 71.594 (917241/1281167) | Lr: 0.005397571904547165
[2022-06-20 08:58:32,607] Test: Loss: 0.969 | Acc: 75.888 (37944/50000)
[2022-06-20 08:58:32,608] Saving..
[2022-06-20 08:58:32,683] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 08:58:32,684] Epoch: 452
[2022-06-20 09:16:15,169] Train: Loss: 1.187 | Acc: 71.751 (919250/1281167) | Lr: 0.005033444005351463
[2022-06-20 09:17:03,896] Test: Loss: 0.973 | Acc: 75.670 (37835/50000)
[2022-06-20 09:17:03,897] Epoch: 453
[2022-06-20 09:34:50,108] Train: Loss: 1.182 | Acc: 71.848 (920499/1281167) | Lr: 0.004681951705872932
[2022-06-20 09:35:40,288] Test: Loss: 0.967 | Acc: 75.928 (37964/50000)
[2022-06-20 09:35:40,289] Saving..
[2022-06-20 09:35:40,405] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 09:35:40,406] Epoch: 454
[2022-06-20 09:53:37,488] Train: Loss: 1.178 | Acc: 71.956 (921876/1281167) | Lr: 0.004343110062871961
[2022-06-20 09:54:25,839] Test: Loss: 0.968 | Acc: 75.854 (37927/50000)
[2022-06-20 09:54:25,841] Epoch: 455
[2022-06-20 10:12:12,038] Train: Loss: 1.176 | Acc: 72.003 (922485/1281167) | Lr: 0.004016933591196727
[2022-06-20 10:13:01,789] Test: Loss: 0.959 | Acc: 76.214 (38107/50000)
[2022-06-20 10:13:01,789] Saving..
[2022-06-20 10:13:01,866] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 10:13:01,867] Epoch: 456
[2022-06-20 10:30:44,461] Train: Loss: 1.169 | Acc: 72.132 (924130/1281167) | Lr: 0.003703436263161675
[2022-06-20 10:31:33,009] Test: Loss: 0.963 | Acc: 76.022 (38011/50000)
[2022-06-20 10:31:33,010] Epoch: 457
[2022-06-20 10:49:16,610] Train: Loss: 1.168 | Acc: 72.188 (924843/1281167) | Lr: 0.0034026315079488997
[2022-06-20 10:50:05,606] Test: Loss: 0.961 | Acc: 76.034 (38017/50000)
[2022-06-20 10:50:05,607] Epoch: 458
[2022-06-20 11:07:50,567] Train: Loss: 1.162 | Acc: 72.247 (925610/1281167) | Lr: 0.0031145322110330566
[2022-06-20 11:08:40,575] Test: Loss: 0.957 | Acc: 76.082 (38041/50000)
[2022-06-20 11:08:40,576] Epoch: 459
[2022-06-20 11:26:39,649] Train: Loss: 1.159 | Acc: 72.358 (927026/1281167) | Lr: 0.0028391507136290403
[2022-06-20 11:27:28,058] Test: Loss: 0.959 | Acc: 76.078 (38039/50000)
[2022-06-20 11:27:28,059] Epoch: 460
[2022-06-20 11:45:11,763] Train: Loss: 1.155 | Acc: 72.481 (928598/1281167) | Lr: 0.0025764988121637525
[2022-06-20 11:46:01,025] Test: Loss: 0.957 | Acc: 76.230 (38115/50000)
[2022-06-20 11:46:01,025] Saving..
[2022-06-20 11:46:01,098] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 11:46:01,099] Epoch: 461
[2022-06-20 12:03:42,223] Train: Loss: 1.155 | Acc: 72.471 (928480/1281167) | Lr: 0.0023265877577704455
[2022-06-20 12:04:32,093] Test: Loss: 0.956 | Acc: 76.252 (38126/50000)
[2022-06-20 12:04:32,093] Saving..
[2022-06-20 12:04:32,171] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 12:04:32,172] Epoch: 462
[2022-06-20 12:22:10,474] Train: Loss: 1.148 | Acc: 72.591 (930018/1281167) | Lr: 0.002089428255806885
[2022-06-20 12:23:00,888] Test: Loss: 0.952 | Acc: 76.234 (38117/50000)
[2022-06-20 12:23:00,889] Epoch: 463
[2022-06-20 12:40:44,394] Train: Loss: 1.146 | Acc: 72.656 (930845/1281167) | Lr: 0.0018650304653968564
[2022-06-20 12:41:33,551] Test: Loss: 0.952 | Acc: 76.252 (38126/50000)
[2022-06-20 12:41:33,552] Epoch: 464
[2022-06-20 12:59:11,872] Train: Loss: 1.143 | Acc: 72.718 (931643/1281167) | Lr: 0.00165340399899482
[2022-06-20 13:00:00,303] Test: Loss: 0.946 | Acc: 76.440 (38220/50000)
[2022-06-20 13:00:00,304] Saving..
[2022-06-20 13:00:00,405] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 13:00:00,405] Epoch: 465
[2022-06-20 13:17:48,264] Train: Loss: 1.140 | Acc: 72.722 (931690/1281167) | Lr: 0.0014545579219743146
[2022-06-20 13:18:37,499] Test: Loss: 0.946 | Acc: 76.488 (38244/50000)
[2022-06-20 13:18:37,499] Saving..
[2022-06-20 13:18:37,580] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 13:18:37,581] Epoch: 466
[2022-06-20 13:36:16,954] Train: Loss: 1.136 | Acc: 72.847 (933288/1281167) | Lr: 0.001268500752239375
[2022-06-20 13:37:05,425] Test: Loss: 0.948 | Acc: 76.392 (38196/50000)
[2022-06-20 13:37:05,426] Epoch: 467
[2022-06-20 13:54:50,639] Train: Loss: 1.136 | Acc: 72.903 (934006/1281167) | Lr: 0.001095240459859929
[2022-06-20 13:55:39,521] Test: Loss: 0.946 | Acc: 76.586 (38293/50000)
[2022-06-20 13:55:39,521] Saving..
[2022-06-20 13:55:39,605] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 13:55:39,606] Epoch: 468
[2022-06-20 14:13:47,370] Train: Loss: 1.131 | Acc: 72.989 (935114/1281167) | Lr: 0.000934784466730276
[2022-06-20 14:14:35,792] Test: Loss: 0.946 | Acc: 76.510 (38255/50000)
[2022-06-20 14:14:35,793] Epoch: 469
[2022-06-20 14:32:25,102] Train: Loss: 1.132 | Acc: 72.970 (934864/1281167) | Lr: 0.0007871396462511146
[2022-06-20 14:33:13,580] Test: Loss: 0.945 | Acc: 76.532 (38266/50000)
[2022-06-20 14:33:13,581] Epoch: 470
[2022-06-20 14:51:05,999] Train: Loss: 1.129 | Acc: 73.039 (935755/1281167) | Lr: 0.0006523123230351489
[2022-06-20 14:51:54,202] Test: Loss: 0.946 | Acc: 76.402 (38201/50000)
[2022-06-20 14:51:54,204] Epoch: 471
[2022-06-20 15:09:51,183] Train: Loss: 1.128 | Acc: 73.023 (935548/1281167) | Lr: 0.0005303082726361429
[2022-06-20 15:10:40,126] Test: Loss: 0.942 | Acc: 76.496 (38248/50000)
[2022-06-20 15:10:40,127] Epoch: 472
[2022-06-20 15:28:41,059] Train: Loss: 1.127 | Acc: 73.092 (936435/1281167) | Lr: 0.00042113272130162266
[2022-06-20 15:29:29,771] Test: Loss: 0.942 | Acc: 76.628 (38314/50000)
[2022-06-20 15:29:29,772] Saving..
[2022-06-20 15:29:29,840] * Saved checkpoint to ./results/14104552/FENet_imagenet.t7
[2022-06-20 15:29:29,841] Epoch: 473
[2022-06-20 15:47:07,175] Train: Loss: 1.126 | Acc: 73.085 (936345/1281167) | Lr: 0.0003247903457487596
[2022-06-20 15:47:56,037] Test: Loss: 0.942 | Acc: 76.580 (38290/50000)
[2022-06-20 15:47:56,038] Epoch: 474
[2022-06-20 16:05:51,690] Train: Loss: 1.124 | Acc: 73.161 (937315/1281167) | Lr: 0.0002412852729643332
[2022-06-20 16:06:41,920] Test: Loss: 0.942 | Acc: 76.562 (38281/50000)
[2022-06-20 16:06:41,921] Epoch: 475
[2022-06-20 16:24:30,698] Train: Loss: 1.124 | Acc: 73.159 (937288/1281167) | Lr: 0.00017062108002767639
[2022-06-20 16:25:20,598] Test: Loss: 0.942 | Acc: 76.574 (38287/50000)
[2022-06-20 16:25:20,600] Epoch: 476
[2022-06-20 16:43:20,964] Train: Loss: 1.121 | Acc: 73.254 (938512/1281167) | Lr: 0.00011280079395769976
[2022-06-20 16:44:10,421] Test: Loss: 0.940 | Acc: 76.618 (38309/50000)
[2022-06-20 16:44:10,422] Epoch: 477
[2022-06-20 17:01:49,469] Train: Loss: 1.123 | Acc: 73.201 (937826/1281167) | Lr: 6.782689158296475e-05
[2022-06-20 17:02:40,272] Test: Loss: 0.942 | Acc: 76.594 (38297/50000)
[2022-06-20 17:02:40,273] Epoch: 478
[2022-06-20 17:20:28,673] Train: Loss: 1.125 | Acc: 73.102 (936559/1281167) | Lr: 3.5701299435769944e-05
[2022-06-20 17:21:18,611] Test: Loss: 0.942 | Acc: 76.576 (38288/50000)
[2022-06-20 17:21:18,612] Epoch: 479
[2022-06-20 17:39:02,343] Train: Loss: 1.119 | Acc: 73.267 (938679/1281167) | Lr: 1.642539366955192e-05
[2022-06-20 17:39:52,142] Test: Loss: 0.940 | Acc: 76.620 (38310/50000)
